@inproceedings{akcayGANomalySemisupervisedAnomaly2019,
  title = {{{GANomaly}}: {{Semi-supervised Anomaly Detection}} via {{Adversarial Training}}},
  shorttitle = {{{GANomaly}}},
  booktitle = {Computer {{Vision}} – {{ACCV}} 2018},
  author = {Akcay, Samet and Atapour-Abarghouei, Amir and Breckon, Toby P.},
  editor = {Jawahar, C. V. and Li, Hongdong and Mori, Greg and Schindler, Konrad},
  date = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {622--637},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-20893-6_39},
  abstract = {Anomaly detection is a classical problem in computer vision, namely the determination of the normal from the abnormal when datasets are highly biased towards one class (normal) due to the insufficient sample size of the other class (abnormal). While this can be addressed as a supervised learning problem, a significantly more challenging problem is that of detecting the unknown/unseen anomaly case that takes us instead into the space of a one-class, semi-supervised learning paradigm. We introduce such a novel anomaly detection model, by using a conditional generative adversarial network that jointly learns the generation of high-dimensional image space and the inference of latent space. Employing encoder-decoder-encoder sub-networks in the generator network enables the model to map the input image to a lower dimension vector, which is then used to reconstruct the generated output image. The use of the additional encoder network maps this generated image to its latent representation. Minimizing the distance between these images and the latent vectors during training aids in learning the data distribution for the normal samples. As a result, a larger distance metric from this learned data distribution at inference time is indicative of an outlier from that distribution—an anomaly. Experimentation over several benchmark datasets, from varying domains, shows the model efficacy and superiority over previous state-of-the-art approaches.},
  isbn = {978-3-030-20893-6},
  langid = {english},
  keywords = {Anomaly detection,Generative Adversarial Networks,Semi-supervised learning,X-ray security imagery},
  file = {/Users/youg/Zotero/storage/B5X887A9/Akcay 等 - 2019 - GANomaly Semi-supervised Anomaly Detection via Ad.pdf}
}

@inproceedings{akcaySkipGANomalySkipConnected2019,
  title = {Skip-{{GANomaly}}: {{Skip Connected}} and {{Adversarially Trained Encoder-Decoder Anomaly Detection}}},
  shorttitle = {Skip-{{GANomaly}}},
  booktitle = {2019 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  author = {Akçay, Samet and Atapour-Abarghouei, Amir and Breckon, Toby P.},
  date = {2019-07},
  pages = {1--8},
  issn = {2161-4407},
  doi = {10.1109/IJCNN.2019.8851808},
  abstract = {Despite inherent ill-definition, anomaly detection is a research endeavour of great interest within machine learning and visual scene understanding alike. Most commonly, anomaly detection is considered as the detection of outliers within a given data distribution based on some measure of normality. The most significant challenge in real-world anomaly detection problems is that available data is highly imbalanced towards normality (i.e. non-anomalous) and contains at most a sub-set of all possible anomalous samples - hence limiting the use of well-established supervised learning methods. By contrast, we introduce an unsupervised anomaly detection model, trained only on the normal (non-anomalous, plentiful) samples in order to learn the normality distribution of the domain, and hence detect abnormality based on deviation from this model. Our proposed approach employs an encoder-decoder convolutional neural network with skip connections to thoroughly capture the multi-scale distribution of the normal data distribution in image space. Furthermore, utilizing an adversarial training scheme for this chosen architecture provides superior reconstruction both within image space and a lower-dimensional embedding vector space encoding. Minimizing the reconstruction error metric within both the image and hidden vector spaces during training aids the model to learn the distribution of normality as required. Higher reconstruction metrics during subsequent test and deployment are thus indicative of a deviation from this normal distribution, hence indicative of an anomaly. Experimentation over established anomaly detection benchmarks and challenging real-world datasets, within the context of X-ray security screening, shows the unique promise of such a proposed approach.},
  eventtitle = {2019 {{International Joint Conference}} on {{Neural Networks}} ({{IJCNN}})},
  keywords = {Anomaly detection,Anomaly Detection,Gallium nitride,GANomaly,Gaussian distribution,Generative adversarial networks,Generative Adversarial Networks,Generators,Image reconstruction,Skip Connections,Training,X-ray Security Screening},
  file = {/Users/youg/Zotero/storage/6S62A4MH/Akçay 等 - 2019 - Skip-GANomaly Skip Connected and Adversarially Tr.pdf;/Users/youg/Zotero/storage/5JUTGM3S/8851808.html}
}

@article{banabilahFederatedLearningReview2022,
  title = {Federated Learning Review: {{Fundamentals}}, Enabling Technologies, and Future Applications},
  shorttitle = {Federated Learning Review},
  author = {Banabilah, Syreen and Aloqaily, Moayad and Alsayed, Eitaa and Malik, Nida and Jararweh, Yaser},
  date = {2022-11-01},
  journaltitle = {Information Processing \& Management},
  shortjournal = {Information Processing \& Management},
  volume = {59},
  number = {6},
  pages = {103061},
  issn = {0306-4573},
  doi = {10.1016/j.ipm.2022.103061},
  url = {https://www.sciencedirect.com/science/article/pii/S0306457322001649},
  urldate = {2023-04-05},
  abstract = {Federated Learning (FL) has been foundational in improving the performance of a wide range of applications since it was first introduced by Google. Some of the most prominent and commonly used FL-powered applications are Android’s Gboard for predictive text and Google Assistant. FL can be defined as a setting that makes on-device, collaborative Machine Learning possible. A wide range of literature has studied FL technical considerations, frameworks, and limitations with several works presenting a survey of the prominent literature on FL. However, prior surveys have focused on technical considerations and challenges of FL, and there has been a limitation in more recent work that presents a comprehensive overview of the status and future trends of FL in applications and markets. In this survey, we introduce the basic fundamentals of FL, describing its underlying technologies, architectures, system challenges, and privacy-preserving methods. More importantly, the contribution of this work is in scoping a wide variety of FL current applications and future trends in technology and markets today. We present a classification and clustering of literature progress in FL in application to technologies including Artificial Intelligence, Internet of Things, blockchain, Natural Language Processing, autonomous vehicles, and resource allocation, as well as in application to market use cases in domains of Data Science, healthcare, education, and industry. We discuss future open directions and challenges in FL within recommendation engines, autonomous vehicles, IoT, battery management, privacy, fairness, personalization, and the role of FL for governments and public sectors. By presenting a comprehensive review of the status and prospects of FL, this work serves as a reference point for researchers and practitioners to explore FL applications under a wide range of domains.},
  langid = {english},
  keywords = {Data privacy,Data security,Decentralized learning,Distributed learning,Federated learning,Machine learning,Mobile edge networks},
  file = {/Users/youg/Zotero/storage/ZLC4ZNF9/Banabilah 等 - 2022 - Federated learning review Fundamentals, enabling .pdf;/Users/youg/Zotero/storage/42CPEUFS/S0306457322001649.html}
}

@inproceedings{baurDeepAutoencodingModels2019,
  title = {Deep {{Autoencoding Models}} for {{Unsupervised Anomaly Segmentation}} in {{Brain MR Images}}},
  booktitle = {Brainlesion: {{Glioma}}, {{Multiple Sclerosis}}, {{Stroke}} and {{Traumatic Brain Injuries}}},
  author = {Baur, Christoph and Wiestler, Benedikt and Albarqouni, Shadi and Navab, Nassir},
  editor = {Crimi, Alessandro and Bakas, Spyridon and Kuijf, Hugo and Keyvan, Farahani and Reyes, Mauricio and family=Walsum, given=Theo, prefix=van, useprefix=true},
  date = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {161--169},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-11723-8_16},
  abstract = {Reliably modeling normality and differentiating abnormal appearances from normal cases is a very appealing approach for detecting pathologies in medical images. A plethora of such unsupervised anomaly detection approaches has been made in the medical domain, based on statistical methods, content-based retrieval, clustering and recently also deep learning. Previous approaches towards deep unsupervised anomaly detection model local patches of normal anatomy with variants of Autoencoders or GANs, and detect anomalies either as outliers in the learned feature space or from large reconstruction errors. In contrast to these patch-based approaches, we show that deep spatial autoencoding models can be efficiently used to capture normal anatomical variability of entire 2D brain MR slices. A variety of experiments on real MR data containing MS lesions corroborates our hypothesis that we can detect and even delineate anomalies in brain MR images by simply comparing input images to their reconstruction. Results show that constraints on the latent space and adversarial training can further improve the segmentation performance over standard deep representation learning.},
  isbn = {978-3-030-11723-8},
  langid = {english},
  file = {/Users/youg/Zotero/storage/AW6ABSTR/Baur 等 - 2019 - Deep Autoencoding Models for Unsupervised Anomaly .pdf}
}

@article{bengsThreedimensionalDeepLearning2021,
  title = {Three-Dimensional Deep Learning with Spatial Erasing for Unsupervised Anomaly Segmentation in Brain {{MRI}}},
  author = {Bengs, Marcel and Behrendt, Finn and Krüger, Julia and Opfer, Roland and Schlaefer, Alexander},
  date = {2021-09-01},
  journaltitle = {International Journal of Computer Assisted Radiology and Surgery},
  shortjournal = {Int J CARS},
  volume = {16},
  number = {9},
  pages = {1413--1423},
  issn = {1861-6429},
  doi = {10.1007/s11548-021-02451-9},
  url = {https://doi.org/10.1007/s11548-021-02451-9},
  urldate = {2023-04-17},
  abstract = {Brain Magnetic Resonance Images (MRIs) are essential for the diagnosis of neurological diseases. Recently, deep learning methods for unsupervised anomaly detection (UAD) have been proposed for the analysis of brain MRI. These methods rely on healthy brain MRIs and eliminate the requirement of pixel-wise annotated data compared to supervised deep learning. While a wide range of methods for UAD have been proposed, these methods are mostly 2D and only learn from MRI slices, disregarding that brain lesions are inherently 3D and the spatial context of MRI volumes remains unexploited.},
  langid = {english},
  keywords = {3D autoencoder,Anomaly,Brain MRI,Segmentation,Unsupervised},
  file = {/Users/youg/Zotero/storage/C28AU3RG/Bengs 等 - 2021 - Three-dimensional deep learning with spatial erasi.pdf}
}

@inproceedings{bergmannAnomalyDetection3D2023,
  title = {Anomaly {{Detection}} in {{3D Point Clouds Using Deep Geometric Descriptors}}},
  author = {Bergmann, Paul and Sattlegger, David},
  date = {2023},
  pages = {2613--2623},
  url = {https://openaccess.thecvf.com/content/WACV2023/html/Bergmann_Anomaly_Detection_in_3D_Point_Clouds_Using_Deep_Geometric_Descriptors_WACV_2023_paper.html},
  urldate = {2023-04-17},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  langid = {english},
  file = {/Users/youg/Zotero/storage/VG5IPSDE/Bergmann 和 Sattlegger - 2023 - Anomaly Detection in 3D Point Clouds Using Deep Ge.pdf}
}

@inproceedings{bergmannImprovingUnsupervisedDefect2019,
  title = {Improving {{Unsupervised Defect Segmentation}} by {{Applying Structural Similarity}} to {{Autoencoders}}},
  booktitle = {Proceedings of the 14th {{International Joint Conference}} on {{Computer Vision}}, {{Imaging}} and {{Computer Graphics Theory}} and {{Applications}}},
  author = {Bergmann, Paul and Löwe, Sindy and Fauser, Michael and Sattlegger, David and Steger, Carsten},
  date = {2019},
  eprint = {1807.02011},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {372--380},
  doi = {10.5220/0007364503720380},
  url = {http://arxiv.org/abs/1807.02011},
  urldate = {2023-04-17},
  abstract = {Convolutional autoencoders have emerged as popular methods for unsupervised defect segmentation on image data. Most commonly, this task is performed by thresholding a pixel-wise reconstruction error based on an \$\textbackslash ell\^p\$ distance. This procedure, however, leads to large residuals whenever the reconstruction encompasses slight localization inaccuracies around edges. It also fails to reveal defective regions that have been visually altered when intensity values stay roughly consistent. We show that these problems prevent these approaches from being applied to complex real-world scenarios and that it cannot be easily avoided by employing more elaborate architectures such as variational or feature matching autoencoders. We propose to use a perceptual loss function based on structural similarity which examines inter-dependencies between local image regions, taking into account luminance, contrast and structural information, instead of simply comparing single pixel values. It achieves significant performance gains on a challenging real-world dataset of nanofibrous materials and a novel dataset of two woven fabrics over the state of the art approaches for unsupervised defect segmentation that use pixel-wise reconstruction error metrics.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/YNC528GG/Bergmann 等 - 2019 - Improving Unsupervised Defect Segmentation by Appl.pdf;/Users/youg/Zotero/storage/L9KDCKGL/1807.html}
}

@inproceedings{bergmannMVTec3DADDataset2022,
  title = {The {{MVTec 3D-AD Dataset}} for {{Unsupervised 3D Anomaly Detection}} and {{Localization}}},
  booktitle = {Proceedings of the 17th {{International Joint Conference}} on {{Computer Vision}}, {{Imaging}} and {{Computer Graphics Theory}} and {{Applications}}},
  author = {Bergmann, Paul and Jin, Xin and Sattlegger, David and Steger, Carsten},
  date = {2022},
  eprint = {2112.09045},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {202--213},
  doi = {10.5220/0010865000003124},
  url = {http://arxiv.org/abs/2112.09045},
  urldate = {2022-12-07},
  abstract = {We introduce the first comprehensive 3D dataset for the task of unsupervised anomaly detection and localization. It is inspired by real-world visual inspection scenarios in which a model has to detect various types of defects on manufactured products, even if it is trained only on anomaly-free data. There are defects that manifest themselves as anomalies in the geometric structure of an object. These cause significant deviations in a 3D representation of the data. We employed a high-resolution industrial 3D sensor to acquire depth scans of 10 different object categories. For all object categories, we present a training and validation set, each of which solely consists of scans of anomaly-free samples. The corresponding test sets contain samples showing various defects such as scratches, dents, holes, contaminations, or deformations. Precise ground-truth annotations are provided for every anomalous test sample. An initial benchmark of 3D anomaly detection methods on our dataset indicates a considerable room for improvement.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Dataset,notion},
  file = {/Users/youg/Zotero/storage/W6TU8DRG/Bergmann 等 - 2022 - The MVTec 3D-AD Dataset for Unsupervised 3D Anomal.pdf;/Users/youg/Zotero/storage/W3K6S26L/2112.html}
}

@inproceedings{bergmannUninformedStudentsStudentTeacher2020,
  title = {Uninformed {{Students}}: {{Student-Teacher Anomaly Detection With Discriminative Latent Embeddings}}},
  shorttitle = {Uninformed {{Students}}},
  author = {Bergmann, Paul and Fauser, Michael and Sattlegger, David and Steger, Carsten},
  date = {2020},
  pages = {4183--4192},
  url = {https://openaccess.thecvf.com/content_CVPR_2020/html/Bergmann_Uninformed_Students_Student-Teacher_Anomaly_Detection_With_Discriminative_Latent_Embeddings_CVPR_2020_paper.html},
  urldate = {2023-04-17},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  file = {/Users/youg/Zotero/storage/IKZ3HTHL/Bergmann 等 - 2020 - Uninformed Students Student-Teacher Anomaly Detec.pdf}
}

@online{berthelotBEGANBoundaryEquilibrium2017,
  title = {{{BEGAN}}: {{Boundary Equilibrium Generative Adversarial Networks}}},
  shorttitle = {{{BEGAN}}},
  author = {Berthelot, David and Schumm, Thomas and Metz, Luke},
  date = {2017-05-31},
  eprint = {1703.10717},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1703.10717},
  url = {http://arxiv.org/abs/1703.10717},
  urldate = {2023-04-17},
  abstract = {We propose a new equilibrium enforcing method paired with a loss derived from the Wasserstein distance for training auto-encoder based Generative Adversarial Networks. This method balances the generator and discriminator during training. Additionally, it provides a new approximate convergence measure, fast and stable training and high visual quality. We also derive a way of controlling the trade-off between image diversity and visual quality. We focus on the image generation task, setting a new milestone in visual quality, even at higher resolutions. This is achieved while using a relatively simple model architecture and a standard training procedure.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/7SXG3K4C/Berthelot 等 - 2017 - BEGAN Boundary Equilibrium Generative Adversarial.pdf;/Users/youg/Zotero/storage/PEDQAV8P/1703.html}
}

@article{bogachevTriangularTransformationsMeasures2005,
  title = {Triangular Transformations of Measures},
  author = {Bogachev, V. I. and Kolesnikov, A. V. and Medvedev, K. V.},
  date = {2005-04-30},
  journaltitle = {Sbornik: Mathematics},
  shortjournal = {Sb. Math.},
  volume = {196},
  number = {3},
  pages = {309},
  publisher = {{IOP Publishing}},
  issn = {1064-5616},
  doi = {10.1070/SM2005v196n03ABEH000882},
  url = {https://iopscience.iop.org/article/10.1070/SM2005v196n03ABEH000882/meta},
  urldate = {2023-04-18},
  langid = {english},
  file = {/Users/youg/Zotero/storage/4JY6MBV8/Bogachev 等 - 2005 - Triangular transformations of measures.pdf}
}

@article{bradleyUseAreaROC1997,
  title = {The Use of the Area under the {{ROC}} Curve in the Evaluation of Machine Learning Algorithms},
  author = {Bradley, Andrew P.},
  date = {1997-07},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {30},
  number = {7},
  pages = {1145--1159},
  issn = {00313203},
  doi = {10.1016/S0031-3203(96)00142-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320396001422},
  urldate = {2023-02-20},
  abstract = {In this paper we investigate the use of the area under the receiver operating characteristic (ROC) curve (AUC) as a performance measure for machine learning algorithms. As a case study we evaluate six machine learning algorithms (C4.5, Multiscale Classifier, Perceptron, Multi-layer Perceptron, k-Nearest Neighbours, and a Quadratic Discriminant Function) on six "real world" medical diagnostics data sets. We compare and discuss the use of AUC to the more conventional overall accuracy and find that AUC exhibits a number of desirable properties when compared to overall accuracy: increased sensitivity in Analysis of Variance (ANOVA) tests; a standard error that decreased as both AUC and the number of test samples increased; decision threshold independent; and it is invariant to a priori class probabilities. The paper concludes with the recommendation that AUC be used in preference to overall accuracy for "single number" evaluation of machine learning algorithms. © 1997 Pattern Recognition Society. Published by Elsevier Science Ltd.},
  langid = {english},
  keywords = {Accuracy measures,Cross-validation,metrics,notion,Standard error,The area under the ROC curve (AUC),The ROC curve,Wilcoxon statistic},
  file = {/Users/youg/Zotero/storage/48CTZ7QZ/Bradley - 1997 - The use of the area under the ROC curve in the eva.pdf;/Users/youg/Zotero/storage/K2NGQG7Y/Bradley - 1997 - The use of the area under the ROC curve in the eva.pdf;/Users/youg/Zotero/storage/FRKKIJEF/S0031320396001422.html}
}

@article{chenSurfaceDefectDetection2021,
  title = {Surface {{Defect Detection Methods}} for {{Industrial Products}}: {{A Review}}},
  shorttitle = {Surface {{Defect Detection Methods}} for {{Industrial Products}}},
  author = {Chen, Yajun and Ding, Yuanyuan and Zhao, Fan and Zhang, Erhu and Wu, Zhangnan and Shao, Linhao},
  date = {2021-01},
  journaltitle = {Applied Sciences},
  volume = {11},
  number = {16},
  pages = {7657},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2076-3417},
  doi = {10.3390/app11167657},
  url = {https://www.mdpi.com/2076-3417/11/16/7657},
  urldate = {2022-04-26},
  abstract = {The comprehensive intelligent development of the manufacturing industry puts forward new requirements for the quality inspection of industrial products. This paper summarizes the current research status of machine learning methods in surface defect detection, a key part in the quality inspection of industrial products. First, according to the use of surface features, the application of traditional machine vision surface defect detection methods in industrial product surface defect detection is summarized from three aspects: texture features, color features, and shape features. Secondly, the research status of industrial product surface defect detection based on deep learning technology in recent years is discussed from three aspects: supervised method, unsupervised method, and weak supervised method. Then, the common key problems and their solutions in industrial surface defect detection are systematically summarized; the key problems include real-time problem, small sample problem, small target problem, unbalanced sample problem. Lastly, the commonly used datasets of industrial surface defects in recent years are more comprehensively summarized, and the latest research methods on the MVTec AD dataset are compared, so as to provide some reference for the further research and development of industrial surface defect detection technology.},
  issue = {16},
  langid = {english},
  keywords = {deep learning,defect detection,image dataset,industrial products,unbalanced samples},
  file = {/Users/youg/Zotero/storage/CN4G29RV/Chen 等。 - 2021 - Surface Defect Detection Methods for Industrial Pr.pdf;/Users/youg/Zotero/storage/42I8UEFI/7657.html}
}

@online{cohenSubImageAnomalyDetection2021,
  title = {Sub-{{Image Anomaly Detection}} with {{Deep Pyramid Correspondences}}},
  author = {Cohen, Niv and Hoshen, Yedid},
  date = {2021-02-03},
  eprint = {2005.02357},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2005.02357},
  url = {http://arxiv.org/abs/2005.02357},
  urldate = {2023-04-17},
  abstract = {Nearest neighbor (kNN) methods utilizing deep pre-trained features exhibit very strong anomaly detection performance when applied to entire images. A limitation of kNN methods is the lack of segmentation map describing where the anomaly lies inside the image. In this work we present a novel anomaly segmentation approach based on alignment between an anomalous image and a constant number of the similar normal images. Our method, Semantic Pyramid Anomaly Detection (SPADE) uses correspondences based on a multi-resolution feature pyramid. SPADE is shown to achieve state-of-the-art performance on unsupervised anomaly detection and localization while requiring virtually no training time.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/HWER9H7V/Cohen 和 Hoshen - 2021 - Sub-Image Anomaly Detection with Deep Pyramid Corr.pdf;/Users/youg/Zotero/storage/5DLKRM7U/2005.html}
}

@online{collinsFedAvgFineTuning2022,
  title = {{{FedAvg}} with {{Fine Tuning}}: {{Local Updates Lead}} to {{Representation Learning}}},
  shorttitle = {{{FedAvg}} with {{Fine Tuning}}},
  author = {Collins, Liam and Hassani, Hamed and Mokhtari, Aryan and Shakkottai, Sanjay},
  date = {2022-05-26},
  eprint = {2205.13692},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.13692},
  url = {http://arxiv.org/abs/2205.13692},
  urldate = {2023-04-03},
  abstract = {The Federated Averaging (FedAvg) algorithm, which consists of alternating between a few local stochastic gradient updates at client nodes, followed by a model averaging update at the server, is perhaps the most commonly used method in Federated Learning. Notwithstanding its simplicity, several empirical studies have illustrated that the output model of FedAvg, after a few fine-tuning steps, leads to a model that generalizes well to new unseen tasks. This surprising performance of such a simple method, however, is not fully understood from a theoretical point of view. In this paper, we formally investigate this phenomenon in the multi-task linear representation setting. We show that the reason behind generalizability of the FedAvg's output is its power in learning the common data representation among the clients' tasks, by leveraging the diversity among client data distributions via local updates. We formally establish the iteration complexity required by the clients for proving such result in the setting where the underlying shared representation is a linear map. To the best of our knowledge, this is the first such result for any setting. We also provide empirical evidence demonstrating FedAvg's representation learning ability in federated image classification with heterogeneous data.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Optimization},
  file = {/Users/youg/Zotero/storage/5P4ZZS33/Collins 等 - 2022 - FedAvg with Fine Tuning Local Updates Lead to Rep.pdf;/Users/youg/Zotero/storage/3U33TCQ3/2205.html}
}

@inproceedings{dalalHistogramsOrientedGradients2005,
  title = {Histograms of {{Oriented Gradients}} for {{Human Detection}}},
  booktitle = {2005 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'05)},
  author = {Dalal, N. and Triggs, B.},
  date = {2005},
  volume = {1},
  pages = {886--893},
  publisher = {{IEEE}},
  location = {{San Diego, CA, USA}},
  doi = {10.1109/CVPR.2005.177},
  url = {http://ieeexplore.ieee.org/document/1467360/},
  urldate = {2023-03-23},
  eventtitle = {2005 {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}}'05)},
  isbn = {978-0-7695-2372-9},
  file = {/Users/youg/Zotero/storage/NNT2FMPU/Dalal 和 Triggs - 2005 - Histograms of Oriented Gradients for Human Detecti.pdf}
}

@inproceedings{defardPaDiMPatchDistribution2021,
  title = {{{PaDiM}}: {{A Patch Distribution Modeling Framework}} for {{Anomaly Detection}} and {{Localization}}},
  shorttitle = {{{PaDiM}}},
  booktitle = {Pattern {{Recognition}}. {{ICPR International Workshops}} and {{Challenges}}},
  author = {Defard, Thomas and Setkov, Aleksandr and Loesch, Angelique and Audigier, Romaric},
  editor = {Del Bimbo, Alberto and Cucchiara, Rita and Sclaroff, Stan and Farinella, Giovanni Maria and Mei, Tao and Bertini, Marco and Escalante, Hugo Jair and Vezzani, Roberto},
  date = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {475--489},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-68799-1_35},
  abstract = {We present a new framework for Patch Distribution Modeling, PaDiM, to concurrently detect and localize anomalies in images in a one-class learning setting. PaDiM makes use of a pretrained convolutional neural network (CNN) for patch embedding, and of multivariate Gaussian distributions to get a probabilistic representation of the normal class. It also exploits correlations between the different semantic levels of CNN to better localize anomalies. PaDiM outperforms current state-of-the-art approaches for both anomaly detection and localization on the MVTec AD and STC datasets. To match real-world visual industrial inspection, we extend the evaluation protocol to assess performance of anomaly localization algorithms on non-aligned dataset. The state-of-the-art performance and low complexity of PaDiM make it a good candidate for many industrial applications.},
  isbn = {978-3-030-68799-1},
  langid = {english},
  keywords = {Anomaly detection,Anomaly localization,Computer vision},
  file = {/Users/youg/Zotero/storage/I3UM47GX/Defard 等 - 2021 - PaDiM A Patch Distribution Modeling Framework for.pdf}
}

@online{dinhDensityEstimationUsing2017,
  title = {Density Estimation Using {{Real NVP}}},
  author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  date = {2017-02-27},
  eprint = {1605.08803},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1605.08803},
  url = {http://arxiv.org/abs/1605.08803},
  urldate = {2023-04-18},
  abstract = {Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real NVP) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/JVJTAUHE/Dinh 等 - 2017 - Density estimation using Real NVP.pdf;/Users/youg/Zotero/storage/E4YVKW8R/1605.html}
}

@online{dinhNICENonlinearIndependent2015,
  title = {{{NICE}}: {{Non-linear Independent Components Estimation}}},
  shorttitle = {{{NICE}}},
  author = {Dinh, Laurent and Krueger, David and Bengio, Yoshua},
  date = {2015-04-10},
  eprint = {1410.8516},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1410.8516},
  url = {http://arxiv.org/abs/1410.8516},
  urldate = {2023-04-18},
  abstract = {We propose a deep learning framework for modeling complex high-dimensional densities called Non-linear Independent Component Estimation (NICE). It is based on the idea that a good representation is one in which the data has a distribution that is easy to model. For this purpose, a non-linear deterministic transformation of the data is learned that maps it to a latent space so as to make the transformed data conform to a factorized distribution, i.e., resulting in independent latent variables. We parametrize this transformation so that computing the Jacobian determinant and inverse transform is trivial, yet we maintain the ability to learn complex non-linear transformations, via a composition of simple building blocks, each based on a deep neural network. The training criterion is simply the exact log-likelihood, which is tractable. Unbiased ancestral sampling is also easy. We show that this approach yields good generative models on four image datasets and can be used for inpainting.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/LTN8VET5/Dinh 等 - 2015 - NICE Non-linear Independent Components Estimation.pdf;/Users/youg/Zotero/storage/L7KWLE6K/1410.html}
}

@online{donahueAdversarialFeatureLearning2017,
  title = {Adversarial {{Feature Learning}}},
  author = {Donahue, Jeff and Krähenbühl, Philipp and Darrell, Trevor},
  date = {2017-04-03},
  eprint = {1605.09782},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1605.09782},
  url = {http://arxiv.org/abs/1605.09782},
  urldate = {2023-04-17},
  abstract = {The ability of the Generative Adversarial Networks (GANs) framework to learn generative models mapping from simple latent distributions to arbitrarily complex data distributions has been demonstrated empirically, with compelling results showing that the latent space of such generators captures semantic variation in the data distribution. Intuitively, models trained to predict these semantic latent representations given data may serve as useful feature representations for auxiliary problems where semantics are relevant. However, in their existing form, GANs have no means of learning the inverse mapping -- projecting data back into the latent space. We propose Bidirectional Generative Adversarial Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate that the resulting learned feature representation is useful for auxiliary supervised discrimination tasks, competitive with contemporary approaches to unsupervised and self-supervised feature learning.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/AHMAMZXS/Donahue 等 - 2017 - Adversarial Feature Learning.pdf;/Users/youg/Zotero/storage/X844FTEJ/1605.html}
}

@article{erfaniHighdimensionalLargescaleAnomaly2016,
  title = {High-Dimensional and Large-Scale Anomaly Detection Using a Linear One-Class {{SVM}} with Deep Learning},
  author = {Erfani, Sarah M. and Rajasegarar, Sutharshan and Karunasekera, Shanika and Leckie, Christopher},
  date = {2016-10-01},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {58},
  pages = {121--134},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2016.03.028},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320316300267},
  urldate = {2023-04-17},
  abstract = {High-dimensional problem domains pose significant challenges for anomaly detection. The presence of irrelevant features can conceal the presence of anomalies. This problem, known as the ‘curse of dimensionality’, is an obstacle for many anomaly detection techniques. Building a robust anomaly detection model for use in high-dimensional spaces requires the combination of an unsupervised feature extractor and an anomaly detector. While one-class support vector machines are effective at producing decision surfaces from well-behaved feature vectors, they can be inefficient at modelling the variation in large, high-dimensional datasets. Architectures such as deep belief networks (DBNs) are a promising technique for learning robust features. We present a hybrid model where an unsupervised DBN is trained to extract generic underlying features, and a one-class SVM is trained from the features learned by the DBN. Since a linear kernel can be substituted for nonlinear ones in our hybrid model without loss of accuracy, our model is scalable and computationally efficient. The experimental results show that our proposed model yields comparable anomaly detection performance with a deep autoencoder, while reducing its training and testing time by a factor of 3 and 1000, respectively.},
  langid = {english},
  keywords = {Anomaly detection,Deep belief net,Deep learning,Feature extraction,High-dimensional data,One-class SVM,Outlier detection},
  file = {/Users/youg/Zotero/storage/7A7D9UDI/S0031320316300267.html}
}

@article{gengStructuredlight3DSurface2011,
  title = {Structured-Light {{3D}} Surface Imaging: A Tutorial},
  shorttitle = {Structured-Light {{3D}} Surface Imaging},
  author = {Geng, Jason},
  date = {2011-06-30},
  journaltitle = {Advances in Optics and Photonics},
  shortjournal = {Adv. Opt. Photon.},
  volume = {3},
  number = {2},
  pages = {128},
  issn = {1943-8206},
  doi = {10.1364/AOP.3.000128},
  url = {https://opg.optica.org/abstract.cfm?URI=aop-3-2-128},
  urldate = {2023-03-29},
  langid = {english},
  file = {/Users/youg/Zotero/storage/U87JCDRS/Geng - 2011 - Structured-light 3D surface imaging a tutorial.pdf}
}

@article{georgiouSurveyTraditionalDeep2020,
  title = {A Survey of Traditional and Deep Learning-Based Feature Descriptors for High Dimensional Data in Computer Vision},
  author = {Georgiou, Theodoros and Liu, Yu and Chen, Wei and Lew, Michael},
  date = {2020-09},
  journaltitle = {International Journal of Multimedia Information Retrieval},
  shortjournal = {Int J Multimed Info Retr},
  volume = {9},
  number = {3},
  pages = {135--170},
  issn = {2192-6611, 2192-662X},
  doi = {10.1007/s13735-019-00183-w},
  url = {http://link.springer.com/10.1007/s13735-019-00183-w},
  urldate = {2023-01-31},
  abstract = {Higher dimensional data such as video and 3D are the leading edge of multimedia retrieval and computer vision research. In this survey, we give a comprehensive overview and key insights into the state of the art of higher dimensional features from deep learning and also traditional approaches. Current approaches are frequently using 3D information from the sensor or are using 3D in modeling and understanding the 3D world. With the growth of prevalent application areas such as 3D games, self-driving automobiles, health monitoring and sports activity training, a wide variety of new sensors have allowed researchers to develop feature description models beyond 2D. Although higher dimensional data enhance the performance of methods on numerous tasks, they can also introduce new challenges and problems. The higher dimensionality of the data often leads to more complicated structures which present additional problems in both extracting meaningful content and in adapting it for current machine learning algorithms. Due to the major importance of the evaluation process, we also present an overview of the current datasets and benchmarks. Moreover, based on more than 330 papers from this study, we present the major challenges and future directions.},
  langid = {english},
  keywords = {3D local feature descriptor,notion,survey},
  file = {/Users/youg/Zotero/storage/WE3NPRWW/Georgiou 等 - 2020 - A survey of traditional and deep learning-based fe.pdf}
}

@inproceedings{gongMemorizingNormalityDetect2019,
  title = {Memorizing {{Normality}} to {{Detect Anomaly}}: {{Memory-Augmented Deep Autoencoder}} for {{Unsupervised Anomaly Detection}}},
  shorttitle = {Memorizing {{Normality}} to {{Detect Anomaly}}},
  author = {Gong, Dong and Liu, Lingqiao and Le, Vuong and Saha, Budhaditya and Mansour, Moussa Reda and Venkatesh, Svetha and family=Hengel, given=Anton, prefix=van den, useprefix=false},
  date = {2019},
  pages = {1705--1714},
  url = {https://openaccess.thecvf.com/content_ICCV_2019/html/Gong_Memorizing_Normality_to_Detect_Anomaly_Memory-Augmented_Deep_Autoencoder_for_Unsupervised_ICCV_2019_paper.html},
  urldate = {2023-04-17},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}},
  file = {/Users/youg/Zotero/storage/6Q25VE64/Gong 等 - 2019 - Memorizing Normality to Detect Anomaly Memory-Aug.pdf}
}

@inproceedings{gopiFastEfficientProjectionbased2002,
  title = {A Fast and Efficient Projection-Based Approach for Surface Reconstruction},
  booktitle = {Proceedings. {{XV Brazilian Symposium}} on {{Computer Graphics}} and {{Image Processing}}},
  author = {Gopi, M. and Krishnan, S.},
  date = {2002},
  pages = {179--186},
  publisher = {{IEEE Comput. Soc}},
  location = {{Fortaleza-CE, Brazil}},
  doi = {10.1109/SIBGRA.2002.1167141},
  url = {http://ieeexplore.ieee.org/document/1167141/},
  urldate = {2023-03-11},
  abstract = {We present a fast and memory efficient algorithm that generates a manifold triangular mesh S with or without boundary passing through a set of unorganized points P ⊂ R3 with no other additional information. Nothing is assumed about the geometry or topology of the sampled manifold model, except for its reasonable smoothness. The speed of our algorithm is derived from a projection-based approach we use to determine the incident faces on a point. Our algorithm has successfully reconstructed the surfaces of unorganized point clouds of sizes varying from 10,000 to 100,000 in about 3–30 seconds on a 250 MHz, R10000 SGI Onyx2. Our technique can be specialized for different kinds of input and applications. For example, our algorithm can be specialized to handle data from height fields like terrain and range scan, even in the presence of noise. We have successfully generated meshes for range scan data of size 900,000 points in less than 40 seconds.},
  eventtitle = {15th {{Brazilian Symposium}} on {{Computer Graphics}} and {{Image Processing}}},
  isbn = {978-0-7695-1846-6},
  langid = {english},
  keywords = {notion,三角化},
  file = {/Users/youg/Zotero/storage/542V57YJ/Gopi 和 Krishnan - 2002 - A fast and efficient projection-based approach for.pdf}
}

@inproceedings{gudovskiyCFLOWADRealTimeUnsupervised2022,
  title = {{{CFLOW-AD}}: {{Real-Time Unsupervised Anomaly Detection}} with {{Localization}} via {{Conditional Normalizing Flows}}},
  shorttitle = {{{CFLOW-AD}}},
  booktitle = {2022 {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  author = {Gudovskiy, Denis and Ishizaka, Shun and Kozuka, Kazuki},
  date = {2022-01},
  pages = {1819--1828},
  publisher = {{IEEE}},
  location = {{Waikoloa, HI, USA}},
  doi = {10.1109/WACV51458.2022.00188},
  url = {https://ieeexplore.ieee.org/document/9707081/},
  urldate = {2023-03-15},
  abstract = {Unsupervised anomaly detection with localization has many practical applications when labeling is infeasible and, moreover, when anomaly examples are completely missing in the train data. While recently proposed models for such data setup achieve high accuracy metrics, their complexity is a limiting factor for real-time processing. In this paper, we propose a real-time model and analytically derive its relationship to prior methods. Our CFLOW-AD model is based on a conditional normalizing flow framework adopted for anomaly detection with localization. In particular, CFLOW-AD consists of a discriminatively pretrained encoder followed by a multi-scale generative decoders where the latter explicitly estimate likelihood of the encoded features. Our approach results in a computationally and memory-efficient model: CFLOW-AD is faster and smaller by a factor of 10× than prior state-of-the-art with the same input setting. Our experiments on the MVTec dataset show that CFLOW-AD outperforms previous methods by 0.36\% AUROC in detection task, by 1.12\% AUROC and 2.5\% AUPRO in localization task, respectively. We open-source our code with fully reproducible experiments1.},
  eventtitle = {2022 {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}} ({{WACV}})},
  isbn = {978-1-66540-915-5},
  langid = {english},
  keywords = {notion},
  file = {/Users/youg/Zotero/storage/KYNFFV6X/Gudovskiy 等 - 2022 - CFLOW-AD Real-Time Unsupervised Anomaly Detection.pdf}
}

@inproceedings{gulrajaniImprovedTrainingWasserstein2017,
  title = {Improved {{Training}} of {{Wasserstein GANs}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Gulrajani, Ishaan and Ahmed, Faruk and Arjovsky, Martin and Dumoulin, Vincent and Courville, Aaron C},
  date = {2017},
  volume = {30},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/892c3b1c6dccd52936e27cbd0ff683d6-Abstract.html},
  urldate = {2023-04-17},
  abstract = {Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only poor samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models with continuous generators. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.},
  file = {/Users/youg/Zotero/storage/28JNP7EV/Gulrajani 等 - 2017 - Improved Training of Wasserstein GANs.pdf}
}

@article{guoComprehensivePerformanceEvaluation2016,
  title = {A {{Comprehensive Performance Evaluation}} of {{3D Local Feature Descriptors}}},
  author = {Guo, Yulan and Bennamoun, Mohammed and Sohel, Ferdous and Lu, Min and Wan, Jianwei and Kwok, Ngai Ming},
  date = {2016-01},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {Int J Comput Vis},
  volume = {116},
  number = {1},
  pages = {66--89},
  issn = {0920-5691, 1573-1405},
  doi = {10.1007/s11263-015-0824-y},
  url = {http://link.springer.com/10.1007/s11263-015-0824-y},
  urldate = {2023-01-31},
  abstract = {A number of 3D local feature descriptors have been proposed in the literature. It is however, unclear which descriptors are more appropriate for a particular application. A good descriptor should be descriptive, compact, and robust to a set of nuisances. This paper compares ten popular local feature descriptors in the contexts of 3D object recognition, 3D shape retrieval, and 3D modeling. We first evaluate the descriptiveness of these descriptors on eight popular datasets which were acquired using different techniques. We then analyze their compactness using the recall of feature matching per each float value in the descriptor. We also test the robustness of the selected descriptors with respect to support radius variations, Gaussian noise, shot noise, varying mesh resolution, distance to the mesh boundary, keypoint localization error, occlusion, clutter, and dataset size. Moreover, we present the performance results of these descriptors when combined with different 3D keypoint detection methods. We finally analyze the computational efficiency for generating each descriptor.},
  langid = {english},
  keywords = {3D local feature descriptor,benchmark,notion},
  file = {/Users/youg/Zotero/storage/QZPTDZMJ/Guo 等 - 2016 - A Comprehensive Performance Evaluation of 3D Local.pdf}
}

@article{guoNovelLocalSurface2015,
  title = {A Novel Local Surface Feature for {{3D}} Object Recognition under Clutter and Occlusion},
  author = {Guo, Yulan and Sohel, Ferdous and Bennamoun, Mohammed and Wan, Jianwei and Lu, Min},
  date = {2015-02},
  journaltitle = {Information Sciences},
  shortjournal = {Information Sciences},
  volume = {293},
  pages = {196--213},
  issn = {00200255},
  doi = {10.1016/j.ins.2014.09.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025514009219},
  urldate = {2023-01-31},
  abstract = {This paper presents a highly distinctive local surface feature called the TriSI feature for recognizing 3D objects in the presence of clutter and occlusion. For a feature point, we first construct a unique and repeatable Local Reference Frame (LRF) using the implicit geometrical information of neighboring triangular faces. We then generate three signatures from the three orthogonal coordinate axes of the LRF. These signatures are concatenated and then compressed into a TriSI feature. Finally, we propose an effective 3D object recognition algorithm based on hierarchical feature matching. We tested our TriSI feature on two popular datasets. Rigorous experimental results show that the TriSI feature was highly descriptive and outperformed existing algorithms under all levels of Gaussian noise, Laplacian noise, shot noise, varying mesh resolutions, occlusion, and clutter. Moreover, we tested our TriSI-based 3D object recognition algorithm on four standard datasets. The experimental results show that our algorithm achieved the best overall recognition results on these datasets.},
  langid = {english},
  keywords = {3D local feature descriptor,3D object recognition,Clutter,Feature description,Local surface feature,notion,Occlusion,Point-cloud},
  file = {/Users/youg/Zotero/storage/2QRLYCW2/Guo 等 - 2015 - A novel local surface feature for 3D object recogn.pdf;/Users/youg/Zotero/storage/5V84NBKX/S0020025514009219.html}
}

@inproceedings{haddadpourFederatedLearningCompression2021,
  title = {Federated {{Learning}} with {{Compression}}: {{Unified Analysis}} and {{Sharp Guarantees}}},
  shorttitle = {Federated {{Learning}} with {{Compression}}},
  booktitle = {Proceedings of {{The}} 24th {{International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  author = {Haddadpour, Farzin and Kamani, Mohammad Mahdi and Mokhtari, Aryan and Mahdavi, Mehrdad},
  date = {2021-03-18},
  pages = {2350--2358},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v130/haddadpour21a.html},
  urldate = {2023-04-04},
  abstract = {In federated learning, communication cost is often a critical bottleneck to scale up distributed optimization algorithms to collaboratively learn a model from millions of devices with potentially unreliable or limited communication and heterogeneous data distributions. Two notable trends to deal with the communication overhead of federated algorithms are gradient compression and local computation with periodic communication. Despite many attempts, characterizing the relationship between these two approaches has proven elusive. We address this by proposing a set of algorithms with periodical compressed (quantized or sparsified) communication and analyze their convergence properties in both homogeneous and heterogeneous local data distributions settings. For the homogeneous setting, our analysis improves existing bounds by providing tighter convergence rates for both strongly convex and non-convex objective functions. To mitigate data heterogeneity, we introduce a local gradient tracking scheme and obtain sharp convergence rates that match the best-known communication complexities without compression for convex, strongly convex, and nonconvex settings. We complement our theoretical results by demonstrating the effectiveness of our proposed methods on real-world datasets.},
  eventtitle = {International {{Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
  langid = {english},
  keywords = {compression},
  file = {/Users/youg/Zotero/storage/TWHCA6J3/Haddadpour 等 - 2021 - Federated Learning with Compression Unified Analy.pdf;/Users/youg/Zotero/storage/XZPTLSY9/Haddadpour 等 - 2021 - Federated Learning with Compression Unified Analy.pdf}
}

@online{hanFedXUnsupervisedFederated2022,
  title = {{{FedX}}: {{Unsupervised Federated Learning}} with {{Cross Knowledge Distillation}}},
  shorttitle = {{{FedX}}},
  author = {Han, Sungwon and Park, Sungwon and Wu, Fangzhao and Kim, Sundong and Wu, Chuhan and Xie, Xing and Cha, Meeyoung},
  date = {2022-07-19},
  eprint = {2207.09158},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2207.09158},
  url = {http://arxiv.org/abs/2207.09158},
  urldate = {2023-04-03},
  abstract = {This paper presents FedX, an unsupervised federated learning framework. Our model learns unbiased representation from decentralized and heterogeneous local data. It employs a two-sided knowledge distillation with contrastive learning as a core component, allowing the federated system to function without requiring clients to share any data features. Furthermore, its adaptable architecture can be used as an add-on module for existing unsupervised algorithms in federated settings. Experiments show that our model improves performance significantly (1.58--5.52pp) on five unsupervised algorithms.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/AEI5YIM7/Han 等 - 2022 - FedX Unsupervised Federated Learning with Cross K.pdf;/Users/youg/Zotero/storage/EPB5F5ST/2207.html}
}

@inproceedings{heDeepResidualLearning2016,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  date = {2016},
  pages = {770--778},
  url = {https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html},
  urldate = {2023-04-17},
  eventtitle = {Proceedings of the {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  file = {/Users/youg/Zotero/storage/FRFG8WLG/He 等 - 2016 - Deep Residual Learning for Image Recognition.pdf}
}

@inproceedings{heikkilaFourstepCameraCalibration1997,
  title = {A Four-Step Camera Calibration Procedure with Implicit Image Correction},
  booktitle = {Proceedings of {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Heikkila, J. and Silven, O.},
  date = {1997-06},
  pages = {1106--1112},
  issn = {1063-6919},
  doi = {10.1109/CVPR.1997.609468},
  abstract = {In geometrical camera calibration the objective is to determine a set of camera parameters that describe the mapping between 3-D reference coordinates and 2-D image coordinates. Various methods for camera calibration can be found from the literature. However surprisingly little attention has been paid to the whole calibration procedure, i.e., control point extraction from images, model fitting, image correction, and errors originating in these stages. The main interest has been in model fitting, although the other stages are also important. In this paper we present a four-step calibration procedure that is an extension to the two-step method. There is an additional step to compensate for distortion caused by circular features, and a step for correcting the distorted image coordinates. The image correction is performed with an empirical inverse model that accurately compensates for radial and tangential distortions. Finally, a linear method for solving the parameters of the inverse model is presented.},
  eventtitle = {Proceedings of {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  keywords = {Calibration,Cameras,Closed-form solution,Error correction,Geometrical optics,Inverse problems,Machine vision,Mathematical model,Minimization methods,Nonlinear distortion},
  file = {/Users/youg/Zotero/storage/7E7DD7RD/Heikkila 和 Silven - 1997 - A four-step camera calibration procedure with impl.pdf;/Users/youg/Zotero/storage/7NFB3LMS/609468.html}
}

@inproceedings{hintonAutoencodersMinimumDescription1993,
  title = {Autoencoders, {{Minimum Description Length}} and {{Helmholtz Free Energy}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Hinton, Geoffrey E and Zemel, Richard},
  date = {1993},
  volume = {6},
  publisher = {{Morgan-Kaufmann}},
  url = {https://proceedings.neurips.cc/paper/1993/hash/9e3cfc48eccf81a0d57663e129aef3cb-Abstract.html},
  urldate = {2023-04-17},
  abstract = {An autoencoder network uses a set of recognition weights to convert an  input vector into a code vector.  It then uses a set of generative weights to  convert the code vector into an approximate reconstruction of the input  vector.  We derive an objective function for training autoencoders based  on the  Minimum  Description Length  (MDL)  principle.  The aim  is  to  minimize the information required to describe both the code vector and  the reconstruction error.  We  show  that this information  is  minimized  by choosing code vectors stochastically according to a Boltzmann distri(cid:173) bution, where the generative weights define the energy of each possible  code vector given  the input vector.  Unfortunately,  if the code vectors  use distributed representations, it is exponentially expensive to compute  this Boltzmann distribution because it involves all possible code vectors.  We show that the recognition weights of an autoencoder can  be used to  compute an approximation to the Boltzmann distribution and that this ap(cid:173) proximation gives an upper bound on the description length.  Even when  this bound is poor,  it can  be used  as a  Lyapunov function for learning  both the generative and the recognition weights.  We  demonstrate that  this approach can be used to learn factorial codes.},
  file = {/Users/youg/Zotero/storage/GK8562LS/Hinton 和 Zemel - 1993 - Autoencoders, Minimum Description Length and Helmh.pdf}
}

@inproceedings{hoGenerativeAdversarialImitation2016,
  title = {Generative {{Adversarial Imitation Learning}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Ho, Jonathan and Ermon, Stefano},
  date = {2016},
  volume = {29},
  publisher = {{Curran Associates, Inc.}},
  url = {https://proceedings.neurips.cc/paper/2016/hash/cc7e2b878868cbae992d1fb743995d8f-Abstract.html},
  urldate = {2023-04-17},
  abstract = {Consider learning a policy from example expert behavior, without interaction with the expert or access to a reinforcement signal. One approach is to recover the expert's cost function with inverse reinforcement learning, then extract a policy from that cost function with reinforcement learning. This approach is indirect and can be slow. We propose a new general framework for directly extracting a policy from data as if it were obtained by reinforcement learning following inverse reinforcement learning. We show that a certain instantiation of our framework draws an analogy between imitation learning and generative adversarial networks, from which we derive a model-free imitation learning algorithm that obtains significant performance gains over existing model-free  methods in imitating complex behaviors in large, high-dimensional environments.},
  file = {/Users/youg/Zotero/storage/PMFYIPYC/Ho 和 Ermon - 2016 - Generative Adversarial Imitation Learning.pdf}
}

@online{horwitzBackFeatureClassical2022,
  title = {Back to the {{Feature}}: {{Classical 3D Features}} Are ({{Almost}}) {{All You Need}} for {{3D Anomaly Detection}}},
  shorttitle = {Back to the {{Feature}}},
  author = {Horwitz, Eliahu and Hoshen, Yedid},
  date = {2022-11-28},
  eprint = {2203.05550},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2203.05550},
  urldate = {2022-12-09},
  abstract = {Despite significant advances in image anomaly detection and segmentation, few methods use 3D information. We utilize a recently introduced 3D anomaly detection dataset to evaluate whether or not using 3D information is a lost opportunity. First, we present a surprising finding: standard color-only methods outperform all current methods that are explicitly designed to exploit 3D information. This is counter-intuitive as even a simple inspection of the dataset shows that color-only methods are insufficient for images containing geometric anomalies. This motivates the question: how can anomaly detection methods effectively use 3D information? We investigate a range of shape representations including hand-crafted and deep-learning-based; we demonstrate that rotation invariance plays the leading role in the performance. We uncover a simple 3D-only method that beats all recent approaches while not using deep learning, external pre-training datasets, or color information. As the 3D-only method cannot detect color and texture anomalies, we combine it with color-based features, significantly outperforming previous state-of-the-art. Our method, dubbed BTF (Back to the Feature) achieves pixel-wise ROCAUC: 99.3\% and PRO: 96.4\% on MVTec 3D-AD.},
  pubstate = {preprint},
  version = {3},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,notion,核心,框架},
  file = {/Users/youg/Zotero/storage/ABYUBZMX/Horwitz 和 Hoshen - 2022 - Back to the Feature Classical 3D Features are (Al.pdf;/Users/youg/Zotero/storage/5AS3KCHS/2203.html}
}

@incollection{hutchisonUniqueSignaturesHistograms2010,
  title = {Unique {{Signatures}} of {{Histograms}} for {{Local Surface Description}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2010},
  author = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Tombari, Federico and Salti, Samuele and Di Stefano, Luigi},
  editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
  date = {2010},
  volume = {6313},
  pages = {356--369},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-15558-1_26},
  url = {http://link.springer.com/10.1007/978-3-642-15558-1_26},
  urldate = {2023-02-21},
  abstract = {This paper deals with local 3D descriptors for surface matching. First, we categorize existing methods into two classes: Signatures and Histograms. Then, by discussion and experiments alike, we point out the key issues of uniqueness and repeatability of the local reference frame. Based on these observations, we formulate a novel comprehensive proposal for surface representation, which encompasses a new unique and repeatable local reference frame as well as a new 3D descriptor. The latter lays at the intersection between Signatures and Histograms, so as to possibly achieve a better balance between descriptiveness and robustness. Experiments on publicly available datasets as well as on range scans obtained with Spacetime Stereo provide a thorough validation of our proposal.},
  isbn = {978-3-642-15557-4 978-3-642-15558-1},
  langid = {english},
  keywords = {3D local feature descriptor,notion},
  file = {/Users/youg/Zotero/storage/CYTD99LU/Hutchison 等 - 2010 - Unique Signatures of Histograms for Local Surface .pdf}
}

@online{ioffeBatchNormalizationAccelerating2015,
  title = {Batch {{Normalization}}: {{Accelerating Deep Network Training}} by {{Reducing Internal Covariate Shift}}},
  shorttitle = {Batch {{Normalization}}},
  author = {Ioffe, Sergey and Szegedy, Christian},
  date = {2015-03-02},
  eprint = {1502.03167},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1502.03167},
  url = {http://arxiv.org/abs/1502.03167},
  urldate = {2023-04-18},
  abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/8HX6C67V/Ioffe 和 Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf;/Users/youg/Zotero/storage/WCQZ3Q25/1502.html}
}

@online{kingmaAutoEncodingVariationalBayes2022,
  title = {Auto-{{Encoding Variational Bayes}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2022-12-10},
  eprint = {1312.6114},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1312.6114},
  url = {http://arxiv.org/abs/1312.6114},
  urldate = {2023-04-17},
  abstract = {How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/3CZE2AU7/Kingma 和 Welling - 2022 - Auto-Encoding Variational Bayes.pdf;/Users/youg/Zotero/storage/529E7CIS/1312.html}
}

@online{kingmaGlowGenerativeFlow2018,
  title = {Glow: {{Generative Flow}} with {{Invertible}} 1x1 {{Convolutions}}},
  shorttitle = {Glow},
  author = {Kingma, Diederik P. and Dhariwal, Prafulla},
  date = {2018-07-10},
  eprint = {1807.03039},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1807.03039},
  url = {http://arxiv.org/abs/1807.03039},
  urldate = {2023-04-18},
  abstract = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realistic-looking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/69MHIA7D/Kingma 和 Dhariwal - 2018 - Glow Generative Flow with Invertible 1x1 Convolut.pdf;/Users/youg/Zotero/storage/PEJHTTWY/1807.html}
}

@inproceedings{kitamuraExplainableAnomalyDetection2019,
  title = {Explainable {{Anomaly Detection}} via {{Feature-Based Localization}}},
  booktitle = {Artificial {{Neural Networks}} and {{Machine Learning}} – {{ICANN}} 2019: {{Workshop}} and {{Special Sessions}}},
  author = {Kitamura, Shogo and Nonaka, Yuichi},
  editor = {Tetko, Igor V. and Kůrková, Věra and Karpov, Pavel and Theis, Fabian},
  date = {2019},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {408--419},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-30493-5_41},
  abstract = {Deep learning has made remarkable progress in the field of image anomaly detection. An explanation of the validity of the detection is required for practical application. Conventional methods for localizing abnormal regions are mainly based on image reconstruction errors. However, they cannot directly extract specific features from abnormal regions, which limits localization performance. To address this issue, we developed a method for explainable anomaly detection in an unsupervised manner. We trained a feature extractor to extract features that had both the compactness of the normal state and the descriptiveness of the abnormal state for the input images and their reconstructed images. For explainability, our method localized and visualized abnormal regions by accumulating intermediate layers, which led to a significant difference in features extracted from the input image and the reconstructed image. The quantitative results of the defect segmentation and the qualitative results of anomaly localization from experiments on two datasets showed that our method outperformed conventional methods when it came to localizing abnormal regions.},
  isbn = {978-3-030-30493-5},
  langid = {english},
  keywords = {Anomaly detection,Deep learning,Explainable,Localization}
}

@article{kobyzevNormalizingFlowsIntroduction2021,
  title = {Normalizing {{Flows}}: {{An Introduction}} and {{Review}} of {{Current Methods}}},
  shorttitle = {Normalizing {{Flows}}},
  author = {Kobyzev, Ivan and Prince, Simon J. D. and Brubaker, Marcus A.},
  date = {2021-11-01},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  shortjournal = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {43},
  number = {11},
  eprint = {1908.09257},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {3964--3979},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/TPAMI.2020.2992934},
  url = {http://arxiv.org/abs/1908.09257},
  urldate = {2023-03-17},
  abstract = {Normalizing Flows are generative models which produce tractable distributions where both sampling and density evaluation can be efficient and exact. The goal of this survey article is to give a coherent and comprehensive review of the literature around the construction and use of Normalizing Flows for distribution learning. We aim to provide context and explanation of the models, review current state-of-the-art literature, and identify open questions and promising future directions.},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/6N9UQUUJ/Kobyzev 等 - 2021 - Normalizing Flows An Introduction and Review of C.pdf;/Users/youg/Zotero/storage/BS3D7A8A/1908.html}
}

@inproceedings{komotoConsistencyEnsuredBidirectional2020,
  title = {Consistency {{Ensured Bi-directional GAN}} for {{Anomaly Detection}}},
  booktitle = {Frontiers of {{Computer Vision}}},
  author = {Komoto, Kyosuke and Aizawa, Hiroaki and Kato, Kunihito},
  editor = {Ohyama, Wataru and Jung, Soon Ki},
  date = {2020},
  series = {Communications in {{Computer}} and {{Information Science}}},
  pages = {236--247},
  publisher = {{Springer}},
  location = {{Singapore}},
  doi = {10.1007/978-981-15-4818-5_18},
  abstract = {Anomaly detection is a challenging and fundamental issue in computer vision tasks. In recent years, GAN (Generative Adversarial Networks) based anomaly detection methods have achieved remarkable results. But the instability of training of GAN could be considered that decreases the anomaly detection score. In particular, Bi-directional GAN has the following two causes that make the training difficult: the lack of consistency of the mutual mapping between the image space and the latent space, and the difficulty in conditioning by the latent variables of the image. Here we propose a novel GAN-based anomaly detection model. In our model, we introduce the consistency loss for ensuring mutual mappings. Further, we propose introducing the projection discriminator as an alternative of concatenating discriminator in order to perform efficient conditioning in the Bi-directional GAN model. In experiments, we evaluate the effectiveness of our model in a simple dataset and real-world setting dataset and confirmed that our model outperforms the conventional anomaly detection methods.},
  isbn = {9789811548185},
  langid = {english},
  keywords = {Anomaly detection,Generative Adversarial Networks,Projection discriminator}
}

@online{langPointPillarsFastEncoders2019a,
  title = {{{PointPillars}}: {{Fast Encoders}} for {{Object Detection}} from {{Point Clouds}}},
  shorttitle = {{{PointPillars}}},
  author = {Lang, Alex H. and Vora, Sourabh and Caesar, Holger and Zhou, Lubing and Yang, Jiong and Beijbom, Oscar},
  date = {2019-05-06},
  eprint = {1812.05784},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1812.05784},
  url = {http://arxiv.org/abs/1812.05784},
  urldate = {2023-04-18},
  abstract = {Object detection in point clouds is an important aspect of many robotics applications such as autonomous driving. In this paper we consider the problem of encoding a point cloud into a format appropriate for a downstream detection pipeline. Recent literature suggests two types of encoders; fixed encoders tend to be fast but sacrifice accuracy, while encoders that are learned from data are more accurate, but slower. In this work we propose PointPillars, a novel encoder which utilizes PointNets to learn a representation of point clouds organized in vertical columns (pillars). While the encoded features can be used with any standard 2D convolutional detection architecture, we further propose a lean downstream network. Extensive experimentation shows that PointPillars outperforms previous encoders with respect to both speed and accuracy by a large margin. Despite only using lidar, our full detection pipeline significantly outperforms the state of the art, even among fusion methods, with respect to both the 3D and bird's eye view KITTI benchmarks. This detection performance is achieved while running at 62 Hz: a 2 - 4 fold runtime improvement. A faster version of our method matches the state of the art at 105 Hz. These benchmarks suggest that PointPillars is an appropriate encoding for object detection in point clouds.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/CNWXX3N2/Lang 等 - 2019 - PointPillars Fast Encoders for Object Detection f.pdf;/Users/youg/Zotero/storage/U4NDDIJF/1812.html}
}

@article{lelanPerfectDensityModels2021,
  title = {Perfect {{Density Models Cannot Guarantee Anomaly Detection}}},
  author = {Le Lan, Charline and Dinh, Laurent},
  date = {2021-12},
  journaltitle = {Entropy},
  volume = {23},
  number = {12},
  pages = {1690},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1099-4300},
  doi = {10.3390/e23121690},
  url = {https://www.mdpi.com/1099-4300/23/12/1690},
  urldate = {2023-04-18},
  abstract = {Thanks to the tractability of their likelihood, several deep generative models show promise for seemingly straightforward but important applications like anomaly detection, uncertainty estimation, and active learning. However, the likelihood values empirically attributed to anomalies conflict with the expectations these proposed applications suggest. In this paper, we take a closer look at the behavior of distribution densities through the lens of reparametrization and show that these quantities carry less meaningful information than previously thought, beyond estimation issues or the curse of dimensionality. We conclude that the use of these likelihoods for anomaly detection relies on strong and implicit hypotheses, and highlight the necessity of explicitly formulating these assumptions for reliable anomaly detection.},
  issue = {12},
  langid = {english},
  keywords = {anomaly detection,deep generative modeling,probabilistic modeling},
  file = {/Users/youg/Zotero/storage/YSMMJMK8/Le Lan 和 Dinh - 2021 - Perfect Density Models Cannot Guarantee Anomaly De.pdf}
}

@article{liFederatedLearningChallenges2020,
  title = {Federated {{Learning}}: {{Challenges}}, {{Methods}}, and {{Future Directions}}},
  shorttitle = {Federated {{Learning}}},
  author = {Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  date = {2020-05},
  journaltitle = {IEEE Signal Processing Magazine},
  shortjournal = {IEEE Signal Process. Mag.},
  volume = {37},
  number = {3},
  eprint = {1908.07873},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {50--60},
  issn = {1053-5888, 1558-0792},
  doi = {10.1109/MSP.2020.2975749},
  url = {http://arxiv.org/abs/1908.07873},
  urldate = {2023-04-03},
  abstract = {Federated learning involves training statistical models over remote devices or siloed data centers, such as mobile phones or hospitals, while keeping data localized. Training in heterogeneous and potentially massive networks introduces novel challenges that require a fundamental departure from standard approaches for large-scale machine learning, distributed optimization, and privacy-preserving data analysis. In this article, we discuss the unique characteristics and challenges of federated learning, provide a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities.},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/D2ZN8A46/Li 等 - 2020 - Federated Learning Challenges, Methods, and Futur.pdf;/Users/youg/Zotero/storage/I2F2MQRF/1908.html}
}

@online{linDeepGradientCompression2020,
  title = {Deep {{Gradient Compression}}: {{Reducing}} the {{Communication Bandwidth}} for {{Distributed Training}}},
  shorttitle = {Deep {{Gradient Compression}}},
  author = {Lin, Yujun and Han, Song and Mao, Huizi and Wang, Yu and Dally, William J.},
  date = {2020-06-22},
  eprint = {1712.01887},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1712.01887},
  urldate = {2023-04-06},
  abstract = {Large-scale distributed training requires significant communication bandwidth for gradient exchange that limits the scalability of multi-node training, and requires expensive high-bandwidth network infrastructure. The situation gets even worse with distributed training on mobile devices (federated learning), which suffers from higher latency, lower throughput, and intermittent poor connections. In this paper, we find 99.9\% of the gradient exchange in distributed SGD is redundant, and propose Deep Gradient Compression (DGC) to greatly reduce the communication bandwidth. To preserve accuracy during compression, DGC employs four methods: momentum correction, local gradient clipping, momentum factor masking, and warm-up training. We have applied Deep Gradient Compression to image classification, speech recognition, and language modeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, and Librispeech Corpus. On these scenarios, Deep Gradient Compression achieves a gradient compression ratio from 270x to 600x without losing accuracy, cutting the gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from 488MB to 0.74MB. Deep gradient compression enables large-scale distributed training on inexpensive commodity 1Gbps Ethernet and facilitates distributed training on mobile. Code is available at: https://github.com/synxlin/deep-gradient-compression.},
  pubstate = {preprint},
  keywords = {compression,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/G6YTHD3M/Lin 等 - 2020 - Deep Gradient Compression Reducing the Communicat.pdf;/Users/youg/Zotero/storage/W5W7C23D/1712.html}
}

@online{linDefensiveQuantizationWhen2019,
  title = {Defensive {{Quantization}}: {{When Efficiency Meets Robustness}}},
  shorttitle = {Defensive {{Quantization}}},
  author = {Lin, Ji and Gan, Chuang and Han, Song},
  date = {2019-04-17},
  eprint = {1904.08444},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1904.08444},
  urldate = {2023-04-10},
  abstract = {Neural network quantization is becoming an industry standard to efficiently deploy deep learning models on hardware platforms, such as CPU, GPU, TPU, and FPGAs. However, we observe that the conventional quantization approaches are vulnerable to adversarial attacks. This paper aims to raise people's awareness about the security of the quantized models, and we designed a novel quantization methodology to jointly optimize the efficiency and robustness of deep learning models. We first conduct an empirical study to show that vanilla quantization suffers more from adversarial attacks. We observe that the inferior robustness comes from the error amplification effect, where the quantization operation further enlarges the distance caused by amplified noise. Then we propose a novel Defensive Quantization (DQ) method by controlling the Lipschitz constant of the network during quantization, such that the magnitude of the adversarial noise remains non-expansive during inference. Extensive experiments on CIFAR-10 and SVHN datasets demonstrate that our new quantization method can defend neural networks against adversarial examples, and even achieves superior robustness than their full-precision counterparts while maintaining the same hardware efficiency as vanilla quantization approaches. As a by-product, DQ can also improve the accuracy of quantized models without adversarial attack.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/ZYSM8E7A/Lin 等 - 2019 - Defensive Quantization When Efficiency Meets Robu.pdf;/Users/youg/Zotero/storage/VWQXV4QZ/1904.html}
}

@book{liu3DImagingAnalysis2020,
  title = {{{3D Imaging}}, {{Analysis}} and {{Applications}}},
  editor = {Liu, Yonghuai and Pears, Nick and Rosin, Paul L. and Huber, Patrik},
  date = {2020},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-44070-1},
  url = {http://link.springer.com/10.1007/978-3-030-44070-1},
  urldate = {2023-01-31},
  isbn = {978-3-030-44069-5 978-3-030-44070-1},
  langid = {english},
  keywords = {3D local feature descriptor,notion,survey},
  file = {/Users/youg/Zotero/storage/HPIDMTD9/Liu 等 - 2020 - 3D Imaging, Analysis and Applications.pdf}
}

@online{liuRecentAdvancesFederated2023,
  title = {Recent {{Advances}} on {{Federated Learning}}: {{A Systematic Survey}}},
  shorttitle = {Recent {{Advances}} on {{Federated Learning}}},
  author = {Liu, Bingyan and Lv, Nuoyan and Guo, Yuanchun and Li, Yawen},
  date = {2023-01-03},
  eprint = {2301.01299},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2301.01299},
  url = {http://arxiv.org/abs/2301.01299},
  urldate = {2023-04-03},
  abstract = {Federated learning has emerged as an effective paradigm to achieve privacy-preserving collaborative learning among different parties. Compared to traditional centralized learning that requires collecting data from each party, in federated learning, only the locally trained models or computed gradients are exchanged, without exposing any data information. As a result, it is able to protect privacy to some extent. In recent years, federated learning has become more and more prevalent and there have been many surveys for summarizing related methods in this hot research topic. However, most of them focus on a specific perspective or lack the latest research progress. In this paper, we provide a systematic survey on federated learning, aiming to review the recent advanced federated methods and applications from different aspects. Specifically, this paper includes four major contributions. First, we present a new taxonomy of federated learning in terms of the pipeline and challenges in federated scenarios. Second, we summarize federated learning methods into several categories and briefly introduce the state-of-the-art methods under these categories. Third, we overview some prevalent federated learning frameworks and introduce their features. Finally, some potential deficiencies of current methods and several future directions are discussed.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/CG5Q7Z3H/Liu 等 - 2023 - Recent Advances on Federated Learning A Systemati.pdf;/Users/youg/Zotero/storage/R3Z3H8J4/2301.html}
}

@article{loweDistinctiveImageFeatures2004,
  title = {Distinctive {{Image Features}} from {{Scale-Invariant Keypoints}}},
  author = {Lowe, David G.},
  date = {2004-11-01},
  journaltitle = {International Journal of Computer Vision},
  shortjournal = {International Journal of Computer Vision},
  volume = {60},
  number = {2},
  pages = {91--110},
  issn = {1573-1405},
  doi = {10.1023/B:VISI.0000029664.99615.94},
  url = {https://doi.org/10.1023/B:VISI.0000029664.99615.94},
  urldate = {2023-04-17},
  abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
  langid = {english},
  keywords = {image matching,invariant features,object recognition,scale invariance}
}

@article{luoGongyequexianjianceshenduxuexifangfazongshu2022,
  title = {工业缺陷检测深度学习方法综述},
  author = {罗, 东亮 and 蔡, 雨萱 and 杨, 子豪 and 章, 哲彦 and 周, 瑜 and 白, 翔},
  date = {2022},
  journaltitle = {中国科学:信息科学},
  volume = {52},
  number = {06},
  pages = {1002--1039},
  issn = {1674-7267},
  url = {https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2022&filename=PZKX202206006&uniplatform=NZKPT&v=bhhfS-dej-3Z7BWtQ0-dbHBjN-mDDK3soYE-mv0FQ5aHjQIdHCeXOA3ZQBeW7xBD},
  urldate = {2022-11-10},
  abstract = {基于深度学习的工业缺陷检测方法可以降低传统人工质检的成本,提升检测的准确性与效率,因而在智能制造中扮演重要角色,并逐渐成为计算机视觉领域新兴的研究热点之一.其被广泛地应用于无人质检、智能巡检、质量控制等各种生产与运维场景中.本综述旨在对工业缺陷检测的任务定义、难点、挑战、主流方法、公共数据集及评价指标等进行全面归纳,以帮助研究人员快速了解该领域.具体而言,本文首先介绍工业缺陷检测的背景与特点.接着,按照实际数据标注情况,划分出缺陷模式已知、缺陷模式未知与少量缺陷标注3种研究任务设置,并根据方法类型作进一步归纳与分析,探讨了各方法的性能优劣与适用场景,阐明了方法与实际应用需求的关联性.此外,本文...},
  langid = {chinese},
  keywords = {anomaly detection,computer vision,deep learning,defect detection,industrial vision,notion,survey,工业视觉,异常检测,深度学习,缺陷检测,计算机视觉},
  file = {/Users/youg/Zotero/storage/395HEJBS/罗 等 - 2022 - 工业缺陷检测深度学习方法综述.pdf}
}

@online{mammenFederatedLearningOpportunities2021,
  title = {Federated {{Learning}}: {{Opportunities}} and {{Challenges}}},
  shorttitle = {Federated {{Learning}}},
  author = {Mammen, Priyanka Mary},
  date = {2021-01-13},
  eprint = {2101.05428},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2101.05428},
  urldate = {2023-04-05},
  abstract = {Federated Learning (FL) is a concept first introduced by Google in 2016, in which multiple devices collaboratively learn a machine learning model without sharing their private data under the supervision of a central server. This offers ample opportunities in critical domains such as healthcare, finance etc, where it is risky to share private user information to other organisations or devices. While FL appears to be a promising Machine Learning (ML) technique to keep the local data private, it is also vulnerable to attacks like other ML models. Given the growing interest in the FL domain, this report discusses the opportunities and challenges in federated learning.},
  pubstate = {preprint},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/65T3W4JW/Mammen - 2021 - Federated Learning Opportunities and Challenges.pdf;/Users/youg/Zotero/storage/RCYGKLD9/2101.html}
}

@online{mcmahanCommunicationEfficientLearningDeep2023,
  title = {Communication-{{Efficient Learning}} of {{Deep Networks}} from {{Decentralized Data}}},
  author = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and family=Arcas, given=Blaise Agüera, prefix=y, useprefix=false},
  date = {2023-01-26},
  eprint = {1602.05629},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1602.05629},
  urldate = {2023-04-03},
  abstract = {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10–100× as compared to synchronized stochastic gradient descent.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Optimization},
  file = {/Users/youg/Zotero/storage/AV8K2XRU/McMahan 等 - 2023 - Communication-Efficient Learning of Deep Networks .pdf}
}

@article{medvedevCERTAINPROPERTIESTRIANGULAR2008,
  title = {{{CERTAIN PROPERTIES OF TRIANGULAR TRANSFORMATIONS OF MEASURES}}},
  author = {Medvedev, Kirill},
  date = {2008-01-01},
  journaltitle = {Theory of Stochastic Processes},
  shortjournal = {Theory of Stochastic Processes},
  volume = {1},
  abstract = {We study convergence of triangular mappings on Rn, i.e., mappings T such that the ith coordi- nate function Ti depends only on the variables x1;::: ;xi. We show that under broad assumptions the inverse mapping to a canonical triangular transformation is canonical triangular as well. An example is constructed showing that convergence in variation of measures is not sucient for convergence almost everywhere of the associated canonical triangular transformations. Finally, we show that weak convergence of absolutely contin- uous convex measures to an absolutely continuous measure yields convergence in variation. As a corollary, this implies convergence in measure of the associated canonical triangular transformations.},
  file = {/Users/youg/Zotero/storage/EQKHFASY/Medvedev - 2008 - CERTAIN PROPERTIES OF TRIANGULAR TRANSFORMATIONS O.pdf}
}

@article{mehtaFederatedLearningbasedSemantic2022,
  title = {Federated Learning-Based Semantic Segmentation for Pixel-Wise Defect Detection in Additive Manufacturing},
  author = {Mehta, Manan and Shao, Chenhui},
  date = {2022-07-01},
  journaltitle = {Journal of Manufacturing Systems},
  shortjournal = {Journal of Manufacturing Systems},
  volume = {64},
  pages = {197--210},
  issn = {0278-6125},
  doi = {10.1016/j.jmsy.2022.06.010},
  url = {https://www.sciencedirect.com/science/article/pii/S0278612522001054},
  urldate = {2023-04-03},
  abstract = {Semantic segmentation is a promising machine learning (ML) method for highly precise fine-scale defect detection and part qualification in additive manufacturing (AM). Most existing segmentation methods utilize convolutional neural network architectures that require large quantities of training data. However, obtaining sufficient data—both in quality and quantity—to train such models is expensive and time-consuming for individual AM practitioners, which severely limits the deployment of semantic segmentation in a data-scarce production environment. Similar data may be readily available with other AM practitioners that cannot be pooled together for conventional centralized learning (CL) due to its sensitive nature or conflicts of interest. This paper develops a federated learning (FL)-based method to simultaneously alleviate the constraints of data availability and data privacy. A U-Net architecture is created for semantic segmentation and is trained under the FL framework. The effectiveness of the developed FL-based semantic segmentation approach is demonstrated using case studies on layer-wise images from the laser powder bed fusion process. Results show that the proposed technique achieves a comparable defect detection performance with CL, which shares data among manufacturers/clients but does not preserve data privacy, and significantly outperforms individual learning, where each manufacturer trains a model using its own data. Additionally, the impact of data distribution across clients, incentives to participate in FL, and the learning dynamics of FL are discussed in detail. It is found that data diversity within and across clients improves FL performance, and FL does not involve a significantly higher training cost compared to CL. Lastly, transfer learning is shown to enhance FL generalizability, thus allowing more manufacturers with heterogeneous machines or technologies to benefit from participating in a data federation. Overall, this work puts forth FL as a promising paradigm for privacy-preserving collaborative ML in AM process control.},
  langid = {english},
  keywords = {Data privacy,Defect detection,Federated learning,Metal additive manufacturing,Quality,Semantic segmentation},
  file = {/Users/youg/Zotero/storage/5JGDI59R/Mehta 和 Shao - 2022 - Federated learning-based semantic segmentation for.pdf;/Users/youg/Zotero/storage/BJ4F727Z/S0278612522001054.html}
}

@article{napoletanoAnomalyDetectionNanofibrous2018,
  title = {Anomaly {{Detection}} in {{Nanofibrous Materials}} by {{CNN-Based Self-Similarity}}},
  author = {Napoletano, Paolo and Piccoli, Flavio and Schettini, Raimondo},
  date = {2018-01},
  journaltitle = {Sensors},
  volume = {18},
  number = {1},
  pages = {209},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1424-8220},
  doi = {10.3390/s18010209},
  url = {https://www.mdpi.com/1424-8220/18/1/209},
  urldate = {2023-04-17},
  abstract = {Automatic detection and localization of anomalies in nanofibrous materials help to reduce the cost of the production process and the time of the post-production visual inspection process. Amongst all the monitoring methods, those exploiting Scanning Electron Microscope (SEM) imaging are the most effective. In this paper, we propose a region-based method for the detection and localization of anomalies in SEM images, based on Convolutional Neural Networks (CNNs) and self-similarity. The method evaluates the degree of abnormality of each subregion of an image under consideration by computing a CNN-based visual similarity with respect to a dictionary of anomaly-free subregions belonging to a training set. The proposed method outperforms the state of the art.},
  issue = {1},
  langid = {english},
  keywords = {anomaly detection,convolutional neural networks,defect detection,industrial quality inspection,nanofibrous materials,quality control},
  file = {/Users/youg/Zotero/storage/7QE9IX6I/Napoletano 等 - 2018 - Anomaly Detection in Nanofibrous Materials by CNN-.pdf}
}

@online{PapersCodeMVTEC,
  title = {Papers with {{Code}} - {{MVTEC 3D-AD Dataset}}},
  url = {https://paperswithcode.com/dataset/mvtec-3d-ad},
  urldate = {2022-12-08},
  abstract = {MVTec 3D Anomaly Detection Dataset (MVTec 3D-AD) is a comprehensive 3D dataset for the task of unsupervised anomaly detection and localization. It contains over 4000 high-resolution scans acquired by an industrial 3D sensor. Each of the 10 different object categories comprises a set of defect-free training and validation samples and a test set of samples with various kinds of defects. Precise ground-truth annotations are provided for each anomalous test sample.},
  langid = {english},
  keywords = {notion},
  file = {/Users/youg/Zotero/storage/BIGH8JXZ/mvtec-3d-ad.html}
}

@online{radfordUnsupervisedRepresentationLearning2016,
  title = {Unsupervised {{Representation Learning}} with {{Deep Convolutional Generative Adversarial Networks}}},
  author = {Radford, Alec and Metz, Luke and Chintala, Soumith},
  date = {2016-01-07},
  eprint = {1511.06434},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1511.06434},
  url = {http://arxiv.org/abs/1511.06434},
  urldate = {2023-04-17},
  abstract = {In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/ZKZMJBXH/Radford 等 - 2016 - Unsupervised Representation Learning with Deep Con.pdf;/Users/youg/Zotero/storage/JVE6SC9W/1511.html}
}

@online{reisizadehFedPAQCommunicationEfficientFederated2020,
  title = {{{FedPAQ}}: {{A Communication-Efficient Federated Learning Method}} with {{Periodic Averaging}} and {{Quantization}}},
  shorttitle = {{{FedPAQ}}},
  author = {Reisizadeh, Amirhossein and Mokhtari, Aryan and Hassani, Hamed and Jadbabaie, Ali and Pedarsani, Ramtin},
  date = {2020-06-07},
  eprint = {1909.13014},
  eprinttype = {arxiv},
  eprintclass = {cs, math, stat},
  url = {http://arxiv.org/abs/1909.13014},
  urldate = {2023-04-08},
  abstract = {Federated learning is a distributed framework according to which a model is trained over a set of devices, while keeping data localized. This framework faces several systems-oriented challenges which include (i) communication bottleneck since a large number of devices upload their local updates to a parameter server, and (ii) scalability as the federated network consists of millions of devices. Due to these systems challenges as well as issues related to statistical heterogeneity of data and privacy concerns, designing a provably efficient federated learning method is of significant importance yet it remains challenging. In this paper, we present FedPAQ, a communication-efficient Federated Learning method with Periodic Averaging and Quantization. FedPAQ relies on three key features: (1) periodic averaging where models are updated locally at devices and only periodically averaged at the server; (2) partial device participation where only a fraction of devices participate in each round of the training; and (3) quantized message-passing where the edge nodes quantize their updates before uploading to the parameter server. These features address the communications and scalability challenges in federated learning. We also show that FedPAQ achieves near-optimal theoretical guarantees for strongly convex and non-convex loss functions and empirically demonstrate the communication-computation tradeoff provided by our method.},
  pubstate = {preprint},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/YRGVM5J2/Reisizadeh 等 - 2020 - FedPAQ A Communication-Efficient Federated Learni.pdf;/Users/youg/Zotero/storage/GIMS69S7/1909.html}
}

@online{rezendeVariationalInferenceNormalizing2016,
  title = {Variational {{Inference}} with {{Normalizing Flows}}},
  author = {Rezende, Danilo Jimenez and Mohamed, Shakir},
  date = {2016-06-14},
  eprint = {1505.05770},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1505.05770},
  url = {http://arxiv.org/abs/1505.05770},
  urldate = {2023-03-17},
  abstract = {The choice of approximate posterior distribution is one of the core problems in variational inference. Most applications of variational inference employ simple families of posterior approximations in order to allow for efficient inference, focusing on mean-field or other simple structured approximations. This restriction has a significant impact on the quality of inferences made using variational methods. We introduce a new approach for specifying flexible, arbitrarily complex and scalable approximate posterior distributions. Our approximations are distributions constructed through a normalizing flow, whereby a simple initial density is transformed into a more complex one by applying a sequence of invertible transformations until a desired level of complexity is attained. We use this view of normalizing flows to develop categories of finite and infinitesimal flows and provide a unified view of approaches for constructing rich posterior approximations. We demonstrate that the theoretical advantages of having posteriors that better match the true posterior, combined with the scalability of amortized variational approaches, provides a clear improvement in performance and applicability of variational inference.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,NF,Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  file = {/Users/youg/Zotero/storage/C2B72FIM/Rezende 和 Mohamed - 2016 - Variational Inference with Normalizing Flows.pdf;/Users/youg/Zotero/storage/6QZ8KK9T/1505.html}
}

@inproceedings{rippelModelingDistributionNormal2021,
  title = {Modeling the {{Distribution}} of {{Normal Data}} in {{Pre-Trained Deep Features}} for {{Anomaly Detection}}},
  booktitle = {2020 25th {{International Conference}} on {{Pattern Recognition}} ({{ICPR}})},
  author = {Rippel, Oliver and Mertens, Patrick and Merhof, Dorit},
  date = {2021-01},
  pages = {6726--6733},
  issn = {1051-4651},
  doi = {10.1109/ICPR48806.2021.9412109},
  abstract = {Anomaly Detection (AD) in images is a fundamental computer vision problem and refers to identifying images and/or image substructures that deviate significantly from the norm. Popular AD algorithms commonly try to learn a model of normality from scratch using task specific datasets, but are limited to semi-supervised approaches employing mostly normal data due to the inaccessibility of anomalies on a large scale combined with the ambiguous nature of anomaly appearance. We follow an alternative approach and demonstrate that deep feature representations learned by discriminative models on large natural image datasets are well suited to describe normality and detect even subtle anomalies in a transfer learning setting. Our model of normality is established by fitting a multivariate Gaussian (MVG) to deep feature representations of classification networks trained on ImageNet using normal data only. By subsequently applying the Mahalanobis distance as the anomaly score we outperform the current state of the art on the public MVTec AD dataset, achieving an Area Under the Receiver Operating Characteristic curve of 95.8 ± 1.2\% (mean ± SEM) over all 15 classes. We further investigate why the learned representations are discriminative to the AD task using Principal Component Analysis. We find that the principal components containing little variance in normal data are the ones crucial for discriminating between normal and anomalous instances. This gives a possible explanation to the often subpar performance of AD approaches trained from scratch using normal data only. By selectively fitting a MVG to these most relevant components only, we are able to further reduce model complexity while retaining AD performance. We also investigate setting the working point by selecting acceptable False Positive Rate thresholds based on the MVG assumption. Code is publicly available at https://github.com/ORippler/gaussian-ad-mvtec.},
  eventtitle = {2020 25th {{International Conference}} on {{Pattern Recognition}} ({{ICPR}})},
  keywords = {Computer vision,Data models,Feature extraction,Fitting,Receivers,Training,Transfer learning},
  file = {/Users/youg/Zotero/storage/GDDKY5B4/Rippel 等 - 2021 - Modeling the Distribution of Normal Data in Pre-Tr.pdf}
}

@online{rothTotalRecallIndustrial2022,
  title = {Towards {{Total Recall}} in {{Industrial Anomaly Detection}}},
  author = {Roth, Karsten and Pemula, Latha and Zepeda, Joaquin and Schölkopf, Bernhard and Brox, Thomas and Gehler, Peter},
  date = {2022-05-05},
  eprint = {2106.08265},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2106.08265},
  urldate = {2023-01-31},
  abstract = {Being able to spot defective parts is a critical component in large-scale industrial manufacturing. A particular challenge that we address in this work is the cold-start problem: fit a model using nominal (non-defective) example images only. While handcrafted solutions per class are possible, the goal is to build systems that work well simultaneously on many different tasks automatically. The best performing approaches combine embeddings from ImageNet models with an outlier detection model. In this paper, we extend on this line of work and propose \textbackslash textbf\{PatchCore\}, which uses a maximally representative memory bank of nominal patch-features. PatchCore offers competitive inference times while achieving state-of-the-art performance for both detection and localization. On the challenging, widely used MVTec AD benchmark PatchCore achieves an image-level anomaly detection AUROC score of up to \$99.6\textbackslash\%\$, more than halving the error compared to the next best competitor. We further report competitive results on two additional datasets and also find competitive results in the few samples regime.\textbackslash freefootnote\{\$\^*\$ Work done during a research internship at Amazon AWS.\} Code: github.com/amazon-research/patchcore-inspection.},
  pubstate = {preprint},
  keywords = {backbone,Computer Science - Computer Vision and Pattern Recognition,notion},
  file = {/Users/youg/Zotero/storage/77D7B4SQ/Roth 等 - 2022 - Towards Total Recall in Industrial Anomaly Detecti.pdf;/Users/youg/Zotero/storage/SF3SS6BJ/2106.html}
}

@online{rudolphAsymmetricStudentTeacherNetworks2022,
  title = {Asymmetric {{Student-Teacher Networks}} for {{Industrial Anomaly Detection}}},
  author = {Rudolph, Marco and Wehrbein, Tom and Rosenhahn, Bodo and Wandt, Bastian},
  date = {2022-10-18},
  eprint = {2210.07829},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2210.07829},
  urldate = {2022-12-17},
  abstract = {Industrial defect detection is commonly addressed with anomaly detection (AD) methods where no or only incomplete data of potentially occurring defects is available. This work discovers previously unknown problems of student-teacher approaches for AD and proposes a solution, where two neural networks are trained to produce the same output for the defect-free training examples. The core assumption of student-teacher networks is that the distance between the outputs of both networks is larger for anomalies since they are absent in training. However, previous methods suffer from the similarity of student and teacher architecture, such that the distance is undesirably small for anomalies. For this reason, we propose asymmetric student-teacher networks (AST). We train a normalizing flow for density estimation as a teacher and a conventional feed-forward network as a student to trigger large distances for anomalies: The bijectivity of the normalizing flow enforces a divergence of teacher outputs for anomalies compared to normal data. Outside the training distribution the student cannot imitate this divergence due to its fundamentally different architecture. Our AST network compensates for wrongly estimated likelihoods by a normalizing flow, which was alternatively used for anomaly detection in previous work. We show that our method produces state-of-the-art results on the two currently most relevant defect detection datasets MVTec AD and MVTec 3D-AD regarding image-level anomaly detection on RGB and 3D data.},
  pubstate = {preprint},
  version = {2},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,notion},
  file = {/Users/youg/Zotero/storage/H5NK7W2D/Rudolph 等 - 2022 - Asymmetric Student-Teacher Networks for Industrial.pdf;/Users/youg/Zotero/storage/DK9GY8IH/2210.html}
}

@online{rudolphFullyConvolutionalCrossScaleFlows2021,
  title = {Fully {{Convolutional Cross-Scale-Flows}} for {{Image-based Defect Detection}}},
  author = {Rudolph, Marco and Wehrbein, Tom and Rosenhahn, Bodo and Wandt, Bastian},
  date = {2021-10-06},
  eprint = {2110.02855},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2110.02855},
  url = {http://arxiv.org/abs/2110.02855},
  urldate = {2023-03-21},
  abstract = {In industrial manufacturing processes, errors frequently occur at unpredictable times and in unknown manifestations. We tackle the problem of automatic defect detection without requiring any image samples of defective parts. Recent works model the distribution of defect-free image data, using either strong statistical priors or overly simplified data representations. In contrast, our approach handles fine-grained representations incorporating the global and local image context while flexibly estimating the density. To this end, we propose a novel fully convolutional cross-scale normalizing flow (CS-Flow) that jointly processes multiple feature maps of different scales. Using normalizing flows to assign meaningful likelihoods to input samples allows for efficient defect detection on image-level. Moreover, due to the preserved spatial arrangement the latent space of the normalizing flow is interpretable which enables to localize defective regions in the image. Our work sets a new state-of-the-art in image-level defect detection on the benchmark datasets Magnetic Tile Defects and MVTec AD showing a 100\% AUROC on 4 out of 15 classes.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,pretrained},
  file = {/Users/youg/Zotero/storage/JZIPICCJ/Rudolph 等 - 2021 - Fully Convolutional Cross-Scale-Flows for Image-ba.pdf;/Users/youg/Zotero/storage/73P5JXS8/2110.html}
}

@inproceedings{rudolphSameSameDifferNet2021,
  title = {Same {{Same}} but {{DifferNet}}: {{Semi-Supervised Defect Detection With Normalizing Flows}}},
  shorttitle = {Same {{Same}} but {{DifferNet}}},
  author = {Rudolph, Marco and Wandt, Bastian and Rosenhahn, Bodo},
  date = {2021},
  pages = {1907--1916},
  url = {https://openaccess.thecvf.com/content/WACV2021/html/Rudolph_Same_Same_but_DifferNet_Semi-Supervised_Defect_Detection_With_Normalizing_Flows_WACV_2021_paper.html},
  urldate = {2023-04-17},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Winter Conference}} on {{Applications}} of {{Computer Vision}}},
  langid = {english},
  file = {/Users/youg/Zotero/storage/C4TV56IM/Rudolph 等 - 2021 - Same Same but DifferNet Semi-Supervised Defect De.pdf}
}

@inproceedings{ruffDeepOneClassClassification2018,
  title = {Deep {{One-Class Classification}}},
  booktitle = {Proceedings of the 35th {{International Conference}} on {{Machine Learning}}},
  author = {Ruff, Lukas and Vandermeulen, Robert and Goernitz, Nico and Deecke, Lucas and Siddiqui, Shoaib Ahmed and Binder, Alexander and Müller, Emmanuel and Kloft, Marius},
  date = {2018-07-03},
  pages = {4393--4402},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v80/ruff18a.html},
  urldate = {2023-04-17},
  abstract = {Despite the great advances made by deep learning in many machine learning problems, there is a relative dearth of deep learning approaches for anomaly detection. Those approaches which do exist involve networks trained to perform a task other than anomaly detection, namely generative models or compression, which are in turn adapted for use in anomaly detection; they are not trained on an anomaly detection based objective. In this paper we introduce a new anomaly detection method—Deep Support Vector Data Description—, which is trained on an anomaly detection based objective. The adaptation to the deep regime necessitates that our neural network and training procedure satisfy certain properties, which we demonstrate theoretically. We show the effectiveness of our method on MNIST and CIFAR-10 image benchmark datasets as well as on the detection of adversarial examples of GTSRB stop signs.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  file = {/Users/youg/Zotero/storage/KKGZ6SMZ/Ruff 等 - 2018 - Deep One-Class Classification.pdf;/Users/youg/Zotero/storage/ZLD39UDM/Ruff 等 - 2018 - Deep One-Class Classification.pdf}
}

@inproceedings{rusuAligningPointCloud2008,
  title = {Aligning Point Cloud Views Using Persistent Feature Histograms},
  booktitle = {2008 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Rusu, R.B. and Blodow, N. and Marton, Z.C. and Beetz, M.},
  date = {2008-09},
  pages = {3384--3391},
  publisher = {{IEEE}},
  location = {{Nice}},
  doi = {10.1109/IROS.2008.4650967},
  url = {http://ieeexplore.ieee.org/document/4650967/},
  urldate = {2023-02-07},
  abstract = {In this paper we investigate the usage of persistent point feature histograms for the problem of aligning point cloud data views into a consistent global model. Given a collection of noisy point clouds, our algorithm estimates a set of robust 16D features which describe the geometry of each point locally. By analyzing the persistence of the features at different scales, we extract an optimal set which best characterizes a given point cloud. The resulted persistent features are used in an initial alignment algorithm to estimate a rigid transformation that approximately registers the input datasets. The algorithm provides good starting points for iterative registration algorithms such as ICP (Iterative Closest Point), by transforming the datasets to its convergence basin. We show that our approach is invariant to pose and sampling density, and can cope well with noisy data coming from both indoor and outdoor laser scans.},
  eventtitle = {2008 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  isbn = {978-1-4244-2057-5 978-1-4244-2058-2},
  langid = {english},
  keywords = {3D local feature descriptor,notion},
  file = {/Users/youg/Zotero/storage/IVTMLXNJ/Rusu 等 - 2008 - Aligning point cloud views using persistent featur.pdf}
}

@inproceedings{rusuFastPointFeature2009,
  title = {Fast {{Point Feature Histograms}} ({{FPFH}}) for {{3D}} Registration},
  booktitle = {2009 {{IEEE International Conference}} on {{Robotics}} and {{Automation}}},
  author = {Rusu, Radu Bogdan and Blodow, Nico and Beetz, Michael},
  date = {2009-05},
  pages = {3212--3217},
  publisher = {{IEEE}},
  location = {{Kobe}},
  doi = {10.1109/ROBOT.2009.5152473},
  url = {http://ieeexplore.ieee.org/document/5152473/},
  urldate = {2023-02-07},
  abstract = {In our recent work [1], [2], we proposed Point Feature Histograms (PFH) as robust multi-dimensional features which describe the local geometry around a point p for 3D point cloud datasets. In this paper, we modify their mathematical expressions and perform a rigorous analysis on their robustness and complexity for the problem of 3D registration for overlapping point cloud views. More concretely, we present several optimizations that reduce their computation times drastically by either caching previously computed values or by revising their theoretical formulations. The latter results in a new type of local features, called Fast Point Feature Histograms (FPFH), which retain most of the discriminative power of the PFH. Moreover, we propose an algorithm for the online computation of FPFH features for realtime applications. To validate our results we demonstrate their efficiency for 3D registration and propose a new sample consensus based method for bringing two datasets into the convergence basin of a local non-linear optimizer: SAC-IA (SAmple Consensus Initial Alignment).},
  eventtitle = {2009 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  isbn = {978-1-4244-2788-8},
  langid = {english},
  keywords = {3D local feature descriptor,notion},
  file = {/Users/youg/Zotero/storage/IMYHLIRA/Rusu 等 - 2009 - Fast Point Feature Histograms (FPFH) for 3D regist.pdf}
}

@article{rusuSemantic3DObject2010,
  title = {Semantic {{3D Object Maps}} for {{Everyday Manipulation}} in {{Human Living Environments}}},
  author = {Rusu, Radu Bogdan},
  date = {2010-11},
  journaltitle = {KI - Künstliche Intelligenz},
  shortjournal = {Künstl Intell},
  volume = {24},
  number = {4},
  pages = {345--348},
  issn = {0933-1875, 1610-1987},
  doi = {10.1007/s13218-010-0059-6},
  url = {http://link.springer.com/10.1007/s13218-010-0059-6},
  urldate = {2023-03-14},
  langid = {english},
  keywords = {notion,特征提取-法线},
  file = {/Users/youg/Zotero/storage/4NBPBN9D/Rusu - 2010 - Semantic 3D Object Maps for Everyday Manipulation .pdf}
}

@inproceedings{salehiMultiresolutionKnowledgeDistillation2021,
  title = {Multiresolution {{Knowledge Distillation}} for {{Anomaly Detection}}},
  author = {Salehi, Mohammadreza and Sadjadi, Niousha and Baselizadeh, Soroosh and Rohban, Mohammad H. and Rabiee, Hamid R.},
  date = {2021},
  pages = {14902--14912},
  url = {https://openaccess.thecvf.com/content/CVPR2021/html/Salehi_Multiresolution_Knowledge_Distillation_for_Anomaly_Detection_CVPR_2021_paper.html},
  urldate = {2023-04-17},
  eventtitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  langid = {english},
  file = {/Users/youg/Zotero/storage/8R6Z5R3P/Salehi 等 - 2021 - Multiresolution Knowledge Distillation for Anomaly.pdf}
}

@article{salviStateArtStructured2010,
  title = {A State of the Art in Structured Light Patterns for Surface Profilometry},
  author = {Salvi, Joaquim and Fernandez, Sergio and Pribanic, Tomislav and Llado, Xavier},
  date = {2010-08},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {43},
  number = {8},
  pages = {2666--2680},
  issn = {00313203},
  doi = {10.1016/j.patcog.2010.03.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S003132031000124X},
  urldate = {2023-03-29},
  langid = {english}
}

@online{sattlerRobustCommunicationEfficientFederated2019,
  title = {Robust and {{Communication-Efficient Federated Learning}} from {{Non-IID Data}}},
  author = {Sattler, Felix and Wiedemann, Simon and Müller, Klaus-Robert and Samek, Wojciech},
  date = {2019-03-07},
  eprint = {1903.02891},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1903.02891},
  urldate = {2023-04-08},
  abstract = {Federated Learning allows multiple parties to jointly train a deep learning model on their combined data, without any of the participants having to reveal their local data to a centralized server. This form of privacy-preserving collaborative learning however comes at the cost of a significant communication overhead during training. To address this problem, several compression methods have been proposed in the distributed training literature that can reduce the amount of required communication by up to three orders of magnitude. These existing methods however are only of limited utility in the Federated Learning setting, as they either only compress the upstream communication from the clients to the server (leaving the downstream communication uncompressed) or only perform well under idealized conditions such as iid distribution of the client data, which typically can not be found in Federated Learning. In this work, we propose Sparse Ternary Compression (STC), a new compression framework that is specifically designed to meet the requirements of the Federated Learning environment. Our experiments on four different learning tasks demonstrate that STC distinctively outperforms Federated Averaging in common Federated Learning scenarios where clients either a) hold non-iid data, b) use small batch sizes during training, or where c) the number of clients is large and the participation rate in every communication round is low. We furthermore show that even if the clients hold iid data and use medium sized batches for training, STC still behaves pareto-superior to Federated Averaging in the sense that it achieves fixed target accuracies on our benchmarks within both fewer training iterations and a smaller communication budget.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/Y4T7GKDY/Sattler 等 - 2019 - Robust and Communication-Efficient Federated Learn.pdf;/Users/youg/Zotero/storage/BQQS5LWJ/1903.html}
}

@article{schleglFAnoGANFastUnsupervised2019,
  title = {F-{{AnoGAN}}: {{Fast}} Unsupervised Anomaly Detection with Generative Adversarial Networks},
  shorttitle = {F-{{AnoGAN}}},
  author = {Schlegl, Thomas and Seeböck, Philipp and Waldstein, Sebastian M. and Langs, Georg and Schmidt-Erfurth, Ursula},
  date = {2019-05-01},
  journaltitle = {Medical Image Analysis},
  shortjournal = {Medical Image Analysis},
  volume = {54},
  pages = {30--44},
  issn = {1361-8415},
  doi = {10.1016/j.media.2019.01.010},
  url = {https://www.sciencedirect.com/science/article/pii/S1361841518302640},
  urldate = {2022-12-14},
  abstract = {Obtaining expert labels in clinical imaging is difficult since exhaustive annotation is time-consuming. Furthermore, not all possibly relevant markers may be known and sufficiently well described a priori to even guide annotation. While supervised learning yields good results if expert labeled training data is available, the visual variability, and thus the vocabulary of findings, we can detect and exploit, is limited to the annotated lesions. Here, we present fast AnoGAN (f-AnoGAN), a generative adversarial network (GAN) based unsupervised learning approach capable of identifying anomalous images and image segments, that can serve as imaging biomarker candidates. We build a generative model of healthy training data, and propose and evaluate a fast mapping technique of new data to the GAN’s latent space. The mapping is based on a trained encoder, and anomalies are detected via a combined anomaly score based on the building blocks of the trained model – comprising a discriminator feature residual error and an image reconstruction error. In the experiments on optical coherence tomography data, we compare the proposed method with alternative approaches, and provide comprehensive empirical evidence that f-AnoGAN outperforms alternative approaches and yields high anomaly detection accuracy. In addition, a visual Turing test with two retina experts showed that the generated images are indistinguishable from real normal retinal OCT images. The f-AnoGAN code is available at https://github.com/tSchlegl/f-AnoGAN.},
  langid = {english},
  keywords = {Anomaly detection,Optical coherence tomography,Unsupervised learning,Wasserstein generative adversarial network},
  file = {/Users/youg/Zotero/storage/536MH79H/Schlegl 等 - 2019 - f-AnoGAN Fast unsupervised anomaly detection with.pdf;/Users/youg/Zotero/storage/BVHQ4R5C/S1361841518302640.html}
}

@inproceedings{schleglUnsupervisedAnomalyDetection2017,
  title = {Unsupervised {{Anomaly Detection}} with {{Generative Adversarial Networks}} to {{Guide Marker Discovery}}},
  booktitle = {Information {{Processing}} in {{Medical Imaging}}},
  author = {Schlegl, Thomas and Seeböck, Philipp and Waldstein, Sebastian M. and Schmidt-Erfurth, Ursula and Langs, Georg},
  editor = {Niethammer, Marc and Styner, Martin and Aylward, Stephen and Zhu, Hongtu and Oguz, Ipek and Yap, Pew-Thian and Shen, Dinggang},
  date = {2017},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {146--157},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-59050-9_12},
  abstract = {Obtaining models that capture imaging markers relevant for~disease progression and treatment monitoring is challenging. Models are typically based on large amounts of data with annotated examples of known markers aiming at automating detection. High annotation effort and the limitation to a vocabulary of known markers limit the power of such approaches. Here, we perform unsupervised learning to identify anomalies in imaging data as candidates for markers. We propose AnoGAN, a deep convolutional generative adversarial network to learn a manifold of normal anatomical variability, accompanying a novel anomaly scoring scheme based on the mapping from image space to a latent space. Applied to new data, the model labels anomalies, and scores image patches indicating their fit into the learned distribution. Results on optical coherence tomography images of the retina demonstrate that the approach correctly identifies anomalous images, such as images containing retinal fluid or hyperreflective foci.},
  isbn = {978-3-319-59050-9},
  langid = {english},
  keywords = {Anomaly Detection,Image Patch,Latent Space,Optical Coherence Tomography,Query Image},
  file = {/Users/youg/Zotero/storage/AZLDL696/Schlegl 等 - 2017 - Unsupervised Anomaly Detection with Generative Adv.pdf}
}

@inproceedings{simarrovianaUnsupervised3DBrain2021,
  title = {Unsupervised {{3D Brain Anomaly Detection}}},
  booktitle = {Brainlesion: {{Glioma}}, {{Multiple Sclerosis}}, {{Stroke}} and {{Traumatic Brain Injuries}}},
  author = {Simarro Viana, Jaime and family=Rosa, given=Ezequiel, prefix=de la, useprefix=true and Vande Vyvere, Thijs and Robben, David and Sima, Diana M. and family=Investigators, given=CENTER-TBI Participants, prefix=and, useprefix=false},
  editor = {Crimi, Alessandro and Bakas, Spyridon},
  date = {2021},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {133--142},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-72084-1_13},
  abstract = {Anomaly detection (AD) is the identification of data samples that do not fit a learned data distribution. As such, AD systems can help physicians to determine the presence, severity, and extension of a pathology. Deep generative models, such as Generative Adversarial Networks (GANs), can be exploited to capture anatomical variability. Consequently, any outlier (i.e., sample falling outside of the learned distribution) can be detected as an abnormality in an unsupervised fashion. By using this method, we can not only detect expected or known lesions, but we can even unveil previously unrecognized biomarkers. To the best of our knowledge, this study exemplifies the first AD approach that can efficiently handle volumetric data and detect 3D brain anomalies in one single model. Our proposal is a volumetric and high-detail extension of the 2D f-AnoGAN model obtained by combining a state-of-the-art 3D GAN with refinement training steps. In experiments using non-contrast computed tomography images from traumatic brain injury (TBI) patients, the model detects and localizes TBI abnormalities with an area under the ROC curve of \$\$\textbackslash sim \$\$∼75\$\$\textbackslash\%\$\$\%. Moreover, we test the potential of the method for detecting other anomalies such as low quality images, preprocessing inaccuracies, artifacts, and even the presence of post-operative signs (such as a craniectomy or a brain shunt). The method has potential for rapidly labeling abnormalities in massive imaging datasets, as well as identifying new biomarkers.},
  isbn = {978-3-030-72084-1},
  langid = {english},
  keywords = {3D GAN,Anomaly detection,Biomarker discovery,Deep generative networks,Unsupervised learning},
  file = {/Users/youg/Zotero/storage/Q65GXMV7/Simarro Viana 等 - 2021 - Unsupervised 3D Brain Anomaly Detection.pdf}
}

@online{smilkovSmoothGradRemovingNoise2017,
  title = {{{SmoothGrad}}: Removing Noise by Adding Noise},
  shorttitle = {{{SmoothGrad}}},
  author = {Smilkov, Daniel and Thorat, Nikhil and Kim, Been and Viégas, Fernanda and Wattenberg, Martin},
  date = {2017-06-12},
  eprint = {1706.03825},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1706.03825},
  url = {http://arxiv.org/abs/1706.03825},
  urldate = {2023-04-17},
  abstract = {Explaining the output of a deep network remains a challenge. In the case of an image classifier, one type of explanation is to identify pixels that strongly influence the final decision. A starting point for this strategy is the gradient of the class score function with respect to the input image. This gradient can be interpreted as a sensitivity map, and there are several techniques that elaborate on this basic idea. This paper makes two contributions: it introduces SmoothGrad, a simple method that can help visually sharpen gradient-based sensitivity maps, and it discusses lessons in the visualization of these maps. We publish the code for our experiments and a website with our results.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/ZESNKWGF/Smilkov 等 - 2017 - SmoothGrad removing noise by adding noise.pdf;/Users/youg/Zotero/storage/BSPPR7J7/1706.html}
}

@article{tanEfficientNetRethinkingModel,
  title = {{{EfficientNet}}: {{Rethinking Model Scaling}} for {{Convolutional Neural Networks}}},
  author = {Tan, Mingxing and Le, Quoc V},
  abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet.},
  langid = {english},
  keywords = {notion},
  file = {/Users/youg/Zotero/storage/QRKPS4RF/Tan 和 Le - EfficientNet Rethinking Model Scaling for Convolu.pdf}
}

@article{tangAnomalyDetectionNeural2020,
  title = {Anomaly {{Detection Neural Network}} with {{Dual Auto-Encoders GAN}} and {{Its Industrial Inspection Applications}}},
  author = {Tang, Ta-Wei and Kuo, Wei-Han and Lan, Jauh-Hsiang and Ding, Chien-Fang and Hsu, Hakiem and Young, Hong-Tsu},
  date = {2020-01},
  journaltitle = {Sensors},
  volume = {20},
  number = {12},
  pages = {3336},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1424-8220},
  doi = {10.3390/s20123336},
  url = {https://www.mdpi.com/1424-8220/20/12/3336},
  urldate = {2023-04-17},
  abstract = {Recently, researchers have been studying methods to introduce deep learning into automated optical inspection (AOI) systems to reduce labor costs. However, the integration of deep learning in the industry may encounter major challenges such as sample imbalance (defective products that only account for a small proportion). Therefore, in this study, an anomaly detection neural network, dual auto-encoder generative adversarial network (DAGAN), was developed to solve the problem of sample imbalance. With skip-connection and dual auto-encoder architecture, the proposed method exhibited excellent image reconstruction ability and training stability. Three datasets, namely public industrial detection training set, MVTec AD, with mobile phone screen glass and wood defect detection datasets, were used to verify the inspection ability of DAGAN. In addition, training with a limited amount of data was proposed to verify its detection ability. The results demonstrated that the areas under the curve (AUCs) of DAGAN were better than previous generative adversarial network-based anomaly detection models in 13 out of 17 categories in these datasets, especially in categories with high variability or noise. The maximum AUC improvement was 0.250 (toothbrush). Moreover, the proposed method exhibited better detection ability than the U-Net auto-encoder, which indicates the function of discriminator in this application. Furthermore, the proposed method had a high level of AUCs when using only a small amount of training data. DAGAN can significantly reduce the time and cost of collecting and labeling data when it is applied to industrial detection.},
  issue = {12},
  langid = {english},
  keywords = {anomaly detection (AD),automated optical inspection (AOI),defect detection,dual auto-encoder generative adversarial network (DAGAN),generative adversarial network (GAN)},
  file = {/Users/youg/Zotero/storage/WJDGZ3U5/Tang 等 - 2020 - Anomaly Detection Neural Network with Dual Auto-En.pdf}
}

@article{TaoXianJiYuShenDuXueXiDeBiaoMianQueXianJianCeFangFaZongShu2021a,
  title = {基于深度学习的表面缺陷检测方法综述},
  author = {陶显 and 侯伟 and 徐德},
  date = {2021-05-20},
  journaltitle = {自动化学报},
  shortjournal = {zdhxb},
  volume = {47},
  number = {5},
  pages = {1017--1034},
  publisher = {{自动化学报}},
  issn = {0254-4156},
  doi = {10.16383/j.aas.c190811},
  url = {http://www.aas.net.cn/cn/article/doi/10.16383/j.aas.c190811},
  urldate = {2022-04-18},
  file = {/Users/youg/Zotero/storage/4DRNEBHT/陶显 等。 - 2021 - 基于深度学习的表面缺陷检测方法综述.pdf;/Users/youg/Zotero/storage/SM73I7XC/j.aas.html}
}

@inproceedings{tombariCombinedTextureshapeDescriptor2011,
  title = {A Combined Texture-Shape Descriptor for Enhanced {{3D}} Feature Matching},
  booktitle = {2011 18th {{IEEE International Conference}} on {{Image Processing}}},
  author = {Tombari, Federico and Salti, Samuele and Di Stefano, Luigi},
  date = {2011-09},
  pages = {809--812},
  publisher = {{IEEE}},
  location = {{Brussels, Belgium}},
  doi = {10.1109/ICIP.2011.6116679},
  url = {http://ieeexplore.ieee.org/document/6116679/},
  urldate = {2023-02-21},
  abstract = {Motivated by the increasing availability of 3D sensors capable of delivering both shape and texture information, this paper presents a novel descriptor for feature matching in 3D data enriched with texture. The proposed approach stems from the theory of a recently proposed descriptor for 3D data which relies on shape only, and represents its generalization to the case of multiple cues associated with a 3D mesh. The proposed descriptor, dubbed CSHOT, is demonstrated to notably improve the accuracy of feature matching in challenging object recognition scenarios characterized by the presence of clutter and occlusions.},
  eventtitle = {2011 18th {{IEEE International Conference}} on {{Image Processing}} ({{ICIP}} 2011)},
  isbn = {978-1-4577-1303-3 978-1-4577-1304-0 978-1-4577-1302-6},
  langid = {english},
  keywords = {3D local feature descriptor,notion},
  file = {/Users/youg/Zotero/storage/NXFIBPC9/Tombari 等 - 2011 - A combined texture-shape descriptor for enhanced 3.pdf}
}

@article{vanderjeughtRealtimeStructuredLight2016,
  title = {Real-Time Structured Light Profilometry: A Review},
  shorttitle = {Real-Time Structured Light Profilometry},
  author = {Van der Jeught, Sam and Dirckx, Joris J. J.},
  date = {2016-12-01},
  journaltitle = {Optics and Lasers in Engineering},
  shortjournal = {Optics and Lasers in Engineering},
  series = {Digital Optical \& {{Imaging}} Methods in Structural Mechanics},
  volume = {87},
  pages = {18--31},
  issn = {0143-8166},
  doi = {10.1016/j.optlaseng.2016.01.011},
  url = {https://www.sciencedirect.com/science/article/pii/S0143816616000166},
  urldate = {2023-04-18},
  abstract = {The acquisition of high-resolution, real-time three-dimensional surface data of dynamically moving objects has large applicability in many fields. When additional restrictions such as non-invasiveness and non-contact measurement are imposed on the employed profilometry technique, the list of possible candidates is reduced mainly to the broad range of structured light profilometry methods. In this manuscript, the current state-of-the-art in structured light profilometry systems is described, as well as the main advancements in hardware technology and coding strategy that have led to their successful development. A chronological overview of optical profilometry systems that have been reported to perform real-time acquisition, digital signal processing and display of full-field 3D surface maps is presented. The respective operating principles, strengths and weaknesses of these setups are reviewed and the main limitations and future challenges in high-speed optical profilometry are discussed.},
  langid = {english},
  keywords = {Phase unwrapping,Real-time,Review,Structured light profilometry},
  file = {/Users/youg/Zotero/storage/6Z2LWA9F/S0143816616000166.html}
}

@online{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2017-12-05},
  eprint = {1706.03762},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2023-04-18},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/S3I2FSDN/Vaswani 等 - 2017 - Attention Is All You Need.pdf;/Users/youg/Zotero/storage/RDG9CSVS/1706.html}
}

@online{wangFederatedLearningMatched2020,
  title = {Federated {{Learning}} with {{Matched Averaging}}},
  author = {Wang, Hongyi and Yurochkin, Mikhail and Sun, Yuekai and Papailiopoulos, Dimitris and Khazaeni, Yasaman},
  date = {2020-02-15},
  eprint = {2002.06440},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2002.06440},
  urldate = {2023-04-04},
  abstract = {Federated learning allows edge devices to collaboratively learn a shared model while keeping the training data on device, decoupling the ability to do model training from the need to store the data in the cloud. We propose Federated matched averaging (FedMA) algorithm designed for federated learning of modern neural network architectures e.g. convolutional neural networks (CNNs) and LSTMs. FedMA constructs the shared global model in a layer-wise manner by matching and averaging hidden elements (i.e. channels for convolution layers; hidden states for LSTM; neurons for fully connected layers) with similar feature extraction signatures. Our experiments indicate that FedMA not only outperforms popular state-of-the-art federated learning algorithms on deep CNN and LSTM architectures trained on real world datasets, but also reduces the overall communication burden.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Optimization,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/D8HDFFFA/Wang 等 - 2020 - Federated Learning with Matched Averaging.pdf;/Users/youg/Zotero/storage/KG3MKJRE/2002.html}
}

@article{wangGuangzhajiegouguangxitongceliangwuchayunihejingduyanjiu2020,
  title = {光栅结构光系统测量误差与拟合精度研究},
  author = {王, 潇 and 刘, 育梁 and 李, 丽艳},
  date = {2020},
  journaltitle = {中国激光},
  volume = {47},
  number = {6},
  pages = {202--212},
  issn = {0258-7025},
  url = {https://kns.cnki.net/kcms2/article/abstract?v=3uoqIhG8C44YLTlOAiTRKibYlV5Vjs7i8oRR1PAr7RxjuAJk4dHXotztXGrpok8KM5OOLnC37fKFKv2ByM5_u4gq3u7pDJK_&uniplatform=NZKPT},
  urldate = {2023-03-07},
  abstract = {针对光栅结构光系统测量误差对拟合结果的影响,提出了一种基于测量环境的误差确定方法。统计不同光源环境及测量距离下的高度测量误差,利用参数或非参数拟合获取其概率密度函数,将上述误差连同平面测量误差一起添加至理想平面模型,通过最小二乘法仿真计算出模型的法向量及定点坐标。实验结果表明:该方法得到的模型参数与根据真实测量数据计算得到的数值基本一致,法向及定点误差分别低于0.001 rad和0.233 mm;所提方法能有效解决光栅结构光系统在不同环境下测量结果精确度不高的问题,此外还能应对实际点云因数据缺失等因素而难以实现高精度拟合的情况,为后续误差校正提供依据。},
  langid = {chinese},
  keywords = {fringe structured light,least squares method,measurement error,model fitting,notion,probability distribution,光栅结构光,最小二乘法 measurement,概率分布,模型拟合,测量,测量误差}
}

@article{wuFedKDCommunicationEfficient2022,
  title = {{{FedKD}}: {{Communication Efficient Federated Learning}} via {{Knowledge Distillation}}},
  shorttitle = {{{FedKD}}},
  author = {Wu, Chuhan and Wu, Fangzhao and Lyu, Lingjuan and Huang, Yongfeng and Xie, Xing},
  date = {2022-04-19},
  journaltitle = {Nature Communications},
  shortjournal = {Nat Commun},
  volume = {13},
  number = {1},
  eprint = {2108.13323},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {2032},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-29763-x},
  url = {http://arxiv.org/abs/2108.13323},
  urldate = {2023-04-03},
  abstract = {Federated learning is widely used to learn intelligent models from decentralized data. In federated learning, clients need to communicate their local model updates in each iteration of model learning. However, model updates are large in size if the model contains numerous parameters, and there usually needs many rounds of communication until model converges. Thus, the communication cost in federated learning can be quite heavy. In this paper, we propose a communication efficient federated learning method based on knowledge distillation. Instead of directly communicating the large models between clients and server, we propose an adaptive mutual distillation framework to reciprocally learn a student and a teacher model on each client, where only the student model is shared by different clients and updated collaboratively to reduce the communication cost. Both the teacher and student on each client are learned on its local data and the knowledge distilled from each other, where their distillation intensities are controlled by their prediction quality. To further reduce the communication cost, we propose a dynamic gradient approximation method based on singular value decomposition to approximate the exchanged gradients with dynamic precision. Extensive experiments on benchmark datasets in different tasks show that our approach can effectively reduce the communication cost and achieve competitive results.},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/NVNA97SY/Wu 等 - 2022 - FedKD Communication Efficient Federated Learning .pdf;/Users/youg/Zotero/storage/YJKCNGJC/2108.html}
}

@article{yangEffectSpatialInformation2017,
  title = {The Effect of Spatial Information Characterization on {{3D}} Local Feature Descriptors: {{A}} Quantitative Evaluation},
  shorttitle = {The Effect of Spatial Information Characterization on {{3D}} Local Feature Descriptors},
  author = {Yang, Jiaqi and Zhang, Qian and Cao, Zhiguo},
  date = {2017-06},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {66},
  pages = {375--391},
  issn = {00313203},
  doi = {10.1016/j.patcog.2017.01.017},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320317300183},
  urldate = {2023-01-31},
  abstract = {Designing local feature descriptors for 3D objects is a fundamental yet challenging task in 3D computer vision. Both geometry and spatial information descriptions are critical for a 3D local descriptor, while most previous studies concentrate on the former one. This paper investigates on how the characterization of spatial information would affect a 3D local descriptor in terms of descriptiveness, robustness, compactness and efficiency. The evaluation process is deployed as follows. First, based on the analysis of representative spatial information characterization methods of existing local shape descriptors, six typical characterization methods with different spatial dimensions and partition principles of spatial information are presented. Second, three geometric attributes, i.e., normal deviation, local depth and shape index, are respectively assigned to each point in the local surface for local geometry description, creating a total of 18 different feature descriptors. Then, a quantitative analysis of performance (i.e., descriptiveness, robustness, compactness and efficiency) for these descriptors is carried out on three benchmark datasets. Grounded on the experimental outcomes, the traits, merits and demerits of each spatial information encoding approach are eventually summarized. This study reveals that different spatial information encoding approaches would bring significant effect on a local shape descriptor with respect to its discriminative power, stability, compactness and efficiency.},
  langid = {english},
  keywords = {3D local feature descriptor,benchmark,notion},
  file = {/Users/youg/Zotero/storage/INISIN8S/Yang 等 - 2017 - The effect of spatial information characterization.pdf}
}

@article{yangTOLDIEffectiveRobust2017,
  title = {{{TOLDI}}: {{An}} Effective and Robust Approach for {{3D}} Local Shape Description},
  shorttitle = {{{TOLDI}}},
  author = {Yang, Jiaqi and Zhang, Qian and Xiao, Yang and Cao, Zhiguo},
  date = {2017-05},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {65},
  pages = {175--187},
  issn = {00313203},
  doi = {10.1016/j.patcog.2016.11.019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320316303776},
  urldate = {2023-02-01},
  langid = {english},
  keywords = {3D local feature descriptor,notion},
  file = {/Users/youg/Zotero/storage/L5R36HME/Yang 等 - 2017 - TOLDI An effective and robust approach for 3D loc.pdf}
}

@inproceedings{yulanguoRoPSLocalFeature2013,
  title = {{{RoPS}}: {{A}} Local Feature Descriptor for {{3D}} Rigid Objects Based on Rotational Projection Statistics},
  shorttitle = {{{RoPS}}},
  booktitle = {2013 1st {{International Conference}} on {{Communications}}, {{Signal Processing}}, and Their {{Applications}} ({{ICCSPA}})},
  author = {{Yulan Guo} and Sohel, F. A. and Bennamoun, M. and {Jianwei Wan} and {Min Lu}},
  date = {2013-02},
  pages = {1--6},
  publisher = {{IEEE}},
  location = {{Sharjah}},
  doi = {10.1109/ICCSPA.2013.6487310},
  url = {http://ieeexplore.ieee.org/document/6487310/},
  urldate = {2023-01-31},
  abstract = {The proper choice of local surface feature descrip­ tors is a key step for an accurate and robust surface matching between different range images. This paper presents a novel 3D feature descriptor for free form objects based on rotational projection statistics. A rotation invariant local reference frame for each feature point is defined by performing an eigenvalue de­ composition on the covariance matrix formed by all points lying on the local surface. The feature descriptor is then constructed by rotationally projecting the neighboring 3D points onto 2D planes and by calculating low order moments and the entropy of the 2D distribution matrix on these planes. Experiments were performed on a dataset comprised of 45 scenes, and the results show that the proposed method is robust to noise and variations in mesh resolution.},
  eventtitle = {2013 1st {{International Conference}} on {{Communications}}, {{Signal Processing}}, and {{Their Applications}} ({{ICCSPA}})},
  isbn = {978-1-4673-2821-0 978-1-4673-2820-3 978-1-4673-2819-7},
  langid = {english},
  keywords = {3D local feature descriptor,notion},
  file = {/Users/youg/Zotero/storage/WFZVP4ZH/Yulan Guo 等 - 2013 - RoPS A local feature descriptor for 3D rigid obje.pdf}
}

@online{zenatiEfficientGANBasedAnomaly2019,
  title = {Efficient {{GAN-Based Anomaly Detection}}},
  author = {Zenati, Houssam and Foo, Chuan Sheng and Lecouat, Bruno and Manek, Gaurav and Chandrasekhar, Vijay Ramaseshan},
  date = {2019-05-01},
  eprint = {1802.06222},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1802.06222},
  url = {http://arxiv.org/abs/1802.06222},
  urldate = {2023-04-17},
  abstract = {Generative adversarial networks (GANs) are able to model the complex highdimensional distributions of real-world data, which suggests they could be effective for anomaly detection. However, few works have explored the use of GANs for the anomaly detection task. We leverage recently developed GAN models for anomaly detection, and achieve state-of-the-art performance on image and network intrusion datasets, while being several hundred-fold faster at test time than the only published GAN-based method.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/2L9JVRCX/Zenati 等 - 2019 - Efficient GAN-Based Anomaly Detection.pdf;/Users/youg/Zotero/storage/FWE4GS5V/1802.html}
}

@online{zengFedLabFlexibleFederated2022,
  title = {{{FedLab}}: {{A Flexible Federated Learning Framework}}},
  shorttitle = {{{FedLab}}},
  author = {Zeng, Dun and Liang, Siqi and Hu, Xiangjing and Wang, Hui and Xu, Zenglin},
  date = {2022-04-22},
  eprint = {2107.11621},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2107.11621},
  url = {http://arxiv.org/abs/2107.11621},
  urldate = {2023-04-03},
  abstract = {Federated learning (FL) is a machine learning field in which researchers try to facilitate model learning process among multiparty without violating privacy protection regulations. Considerable effort has been invested in FL optimization and communication related researches. In this work, we introduce \textbackslash texttt\{FedLab\}, a lightweight open-source framework for FL simulation. The design of \textbackslash texttt\{FedLab\} focuses on FL algorithm effectiveness and communication efficiency. Also, \textbackslash texttt\{FedLab\} is scalable in different deployment scenario. We hope \textbackslash texttt\{FedLab\} could provide flexible API as well as reliable baseline implementations, and relieve the burden of implementing novel approaches for researchers in FL community.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/X62QBHXH/Zeng 等 - 2022 - FedLab A Flexible Federated Learning Framework.pdf;/Users/youg/Zotero/storage/QJUN5JHY/2107.html}
}

@article{zhangFlexibleNewTechnique2000,
  title = {A Flexible New Technique for Camera Calibration},
  author = {Zhang, Z.},
  date = {2000-11},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {22},
  number = {11},
  pages = {1330--1334},
  issn = {1939-3539},
  doi = {10.1109/34.888718},
  abstract = {We propose a flexible technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one more step from laboratory environments to real world use.},
  eventtitle = {{{IEEE Transactions}} on {{Pattern Analysis}} and {{Machine Intelligence}}},
  keywords = {Calibration,Cameras,Closed-form solution,Computer simulation,Computer vision,Layout,Lenses,Maximum likelihood estimation,Nonlinear distortion,Testing},
  file = {/Users/youg/Zotero/storage/AJFRUFVK/888718.html}
}

@inproceedings{zhangNotAllPoints2022,
  title = {Not {{All Points Are Equal}}: {{Learning Highly Efficient Point-based Detectors}} for {{3D LiDAR Point Clouds}}},
  shorttitle = {Not {{All Points Are Equal}}},
  booktitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Zhang, Yifan and Hu, Qingyong and Xu, Guoquan and Ma, Yanxin and Wan, Jianwei and Guo, Yulan},
  date = {2022-06},
  pages = {18931--18940},
  publisher = {{IEEE}},
  location = {{New Orleans, LA, USA}},
  doi = {10.1109/CVPR52688.2022.01838},
  url = {https://ieeexplore.ieee.org/document/9879147/},
  urldate = {2023-01-31},
  abstract = {We study the problem of efficient object detection of 3D LiDAR point clouds. To reduce the memory and computational cost, existing point-based pipelines usually adopt task-agnostic random sampling or farthest point sampling to progressively downsample input point clouds, despite the fact that not all points are equally important to the task of object detection. In particular, the foreground points are inherently more important than background points for object detectors. Motivated by this, we propose a highly-efficient single-stage point-based 3D detector in this paper, termed IA-SSD. The key of our approach is to exploit two learnable, task-oriented, instance-aware downsampling strategies to hierarchically select the foreground points belonging to objects of interest. Additionally, we also introduce a contextual centroid perception module to further estimate precise instance centers. Finally, we build our IA-SSD following the encoder-only architecture for efficiency. Extensive experiments conducted on several large-scale detection benchmarks demonstrate the competitive performance of our IA-SSD. Thanks to the low memory footprint and a high degree of parallelism, it achieves a superior speed of 80+ frames-per-second on the KITTI dataset with a single RTX2080Ti GPU. The code is available at https: //github.com/yifanzhang713/IA-SSD.},
  eventtitle = {2022 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  isbn = {978-1-66546-946-3},
  langid = {english},
  keywords = {3D local feature descriptor,DL,notion},
  file = {/Users/youg/Zotero/storage/6CCZJ4LS/Zhang 等 - 2022 - Not All Points Are Equal Learning Highly Efficien.pdf}
}

@online{zhaoFederatedLearningNonIID2022,
  title = {Federated {{Learning}} with {{Non-IID Data}}},
  author = {Zhao, Yue and Li, Meng and Lai, Liangzhen and Suda, Naveen and Civin, Damon and Chandra, Vikas},
  date = {2022-07-21},
  eprint = {1806.00582},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1806.00582},
  url = {http://arxiv.org/abs/1806.00582},
  urldate = {2023-04-08},
  abstract = {Federated learning enables resource-constrained edge compute devices, such as mobile phones and IoT devices, to learn a shared model for prediction, while keeping the training data local. This decentralized approach to train models provides privacy, security, regulatory and economic benefits. In this work, we focus on the statistical challenge of federated learning when local data is non-IID. We first show that the accuracy of federated learning reduces significantly, by up to 55\% for neural networks trained for highly skewed non-IID data, where each client device trains only on a single class of data. We further show that this accuracy reduction can be explained by the weight divergence, which can be quantified by the earth mover's distance (EMD) between the distribution over classes on each device and the population distribution. As a solution, we propose a strategy to improve training on non-IID data by creating a small subset of data which is globally shared between all the edge devices. Experiments show that accuracy can be increased by 30\% for the CIFAR-10 dataset with only 5\% globally shared data.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/youg/Zotero/storage/RPY6N332/Zhao 等 - 2022 - Federated Learning with Non-IID Data.pdf;/Users/youg/Zotero/storage/Q8ZCC92P/1806.html}
}

@article{zhaoHoPPFNovelLocal2020,
  title = {{{HoPPF}}: {{A}} Novel Local Surface Descriptor for {{3D}} Object Recognition},
  shorttitle = {{{HoPPF}}},
  author = {Zhao, Huan and Tang, Minjie and Ding, Han},
  date = {2020-07},
  journaltitle = {Pattern Recognition},
  shortjournal = {Pattern Recognition},
  volume = {103},
  pages = {107272},
  issn = {00313203},
  doi = {10.1016/j.patcog.2020.107272},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320320300777},
  urldate = {2023-02-01},
  langid = {english},
  keywords = {3D local feature descriptor,notion},
  file = {/Users/youg/Zotero/storage/ICQT7RLI/Zhao 等 - 2020 - HoPPF A novel local surface descriptor for 3D obj.pdf}
}

@online{zhengBenchmarkingUnsupervisedAnomaly2022,
  title = {Benchmarking {{Unsupervised Anomaly Detection}} and {{Localization}}},
  author = {Zheng, Ye and Wang, Xiang and Qi, Yu and Li, Wei and Wu, Liwei},
  date = {2022-05-30},
  eprint = {2205.14852},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2205.14852},
  urldate = {2023-01-31},
  abstract = {Unsupervised anomaly detection and localization, as of one the most practical and challenging problems in computer vision, has received great attention in recent years. From the time the MVTec AD dataset was proposed to the present, new research methods that are constantly being proposed push its precision to saturation. It is the time to conduct a comprehensive comparison of existing methods to inspire further research. This paper extensively compares 13 papers in terms of the performance in unsupervised anomaly detection and localization tasks, and adds a comparison of inference efficiency previously ignored by the community. Meanwhile, analysis of the MVTec AD dataset are also given, especially the label ambiguity that affects the model fails to achieve full marks. Moreover, considering the proposal of the new MVTec 3D-AD dataset, this paper also conducts experiments using the existing state-of-the-art 2D methods on this new dataset, and reports the corresponding results with analysis.},
  pubstate = {preprint},
  version = {1},
  keywords = {backbone,benchmark,Computer Science - Computer Vision and Pattern Recognition,notion},
  file = {/Users/youg/Zotero/storage/RANMLMA4/Zheng 等 - 2022 - Benchmarking Unsupervised Anomaly Detection and Lo.pdf;/Users/youg/Zotero/storage/UCMLL7KM/2205.html}
}

@online{zhouCommunicationefficientFederatedLearning2023,
  title = {Communication-Efficient {{Federated Learning}} with {{Single-Step Synthetic Features Compressor}} for {{Faster Convergence}}},
  author = {Zhou, Yuhao and Shi, Mingjia and Li, Yuanxi and Ye, Qing and Sun, Yanan and Lv, Jiancheng},
  date = {2023-03-18},
  eprint = {2302.13562},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.13562},
  urldate = {2023-04-08},
  abstract = {Reducing communication overhead in federated learning (FL) is challenging but crucial for large-scale distributed privacy-preserving machine learning. While methods utilizing sparsification or others can largely lower the communication overhead, the convergence rate is also greatly compromised. In this paper, we propose a novel method, named single-step synthetic features compressor (3SFC), to achieve communication-efficient FL by directly constructing a tiny synthetic dataset based on raw gradients. Thus, 3SFC can achieve an extremely low compression rate when the constructed dataset contains only one data sample. Moreover, 3SFC's compressing phase utilizes a similarity-based objective function so that it can be optimized with just one step, thereby considerably improving its performance and robustness. In addition, to minimize the compressing error, error feedback (EF) is also incorporated into 3SFC. Experiments on multiple datasets and models suggest that 3SFC owns significantly better convergence rates compared to competing methods with lower compression rates (up to 0.02\%). Furthermore, ablation studies and visualizations show that 3SFC can carry more information than competing methods for every communication round, further validating its effectiveness.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning},
  file = {/Users/youg/Zotero/storage/ZTSL99PB/Zhou 等 - 2023 - Communication-efficient Federated Learning with Si.pdf;/Users/youg/Zotero/storage/2P2T6IAD/2302.html}
}

@inproceedings{zhouEncodingStructureTextureRelation2020,
  title = {Encoding {{Structure-Texture Relation}} with {{P-Net}} for {{Anomaly Detection}} in {{Retinal Images}}},
  booktitle = {Computer {{Vision}} – {{ECCV}} 2020},
  author = {Zhou, Kang and Xiao, Yuting and Yang, Jianlong and Cheng, Jun and Liu, Wen and Luo, Weixin and Gu, Zaiwang and Liu, Jiang and Gao, Shenghua},
  editor = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
  date = {2020},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {360--377},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-58565-5_22},
  abstract = {Anomaly detection in retinal image refers to the identification of abnormality caused by various retinal diseases/lesions, by only leveraging normal images in training phase. Normal images from healthy subjects often have regular structures (e.g., the structured blood vessels in the fundus image, or structured anatomy in optical coherence tomography image). On the contrary, the diseases and lesions often destroy these structures. Motivated by this, we propose to leverage the relation between the image texture and structure to design a deep neural network for anomaly detection. Specifically, we first extract the structure of the retinal images, then we combine both the structure features and the last layer features extracted from original health image to reconstruct the original input healthy image. The image feature provides the texture information and guarantees the uniqueness of the image recovered from the structure. In the end, we further utilize the reconstructed image to extract the structure and measure the difference between structure extracted from original and the reconstructed image. On the one hand, minimizing the reconstruction difference behaves like a regularizer to guarantee that the image is corrected reconstructed. On the other hand, such structure difference can also be used as a metric for normality measurement. The whole network is termed as P-Net because it has a “P” shape. Extensive experiments on RESC dataset and iSee dataset validate the effectiveness of our approach for anomaly detection in retinal images. Further, our method also generalizes well to novel class discovery in retinal images and anomaly detection in real-world images.},
  isbn = {978-3-030-58565-5},
  langid = {english},
  keywords = {Anomaly detection,Novel class discovery,Structure-texture relation},
  file = {/Users/youg/Zotero/storage/UT67YDXI/Zhou 等 - 2020 - Encoding Structure-Texture Relation with P-Net for.pdf}
}
